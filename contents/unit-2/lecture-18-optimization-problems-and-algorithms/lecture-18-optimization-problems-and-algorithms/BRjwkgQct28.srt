1
00:00:00,000 --> 00:00:00,530

2
00:00:00,530 --> 00:00:02,960
The following content is
provided under a Creative

3
00:00:02,960 --> 00:00:04,370
Commons license.

4
00:00:04,370 --> 00:00:07,410
Your support will help MIT
OpenCourseWare continue to

5
00:00:07,410 --> 00:00:11,060
offer high quality educational
resources for free.

6
00:00:11,060 --> 00:00:13,960
To make a donation or view
additional materials from

7
00:00:13,960 --> 00:00:19,790
hundreds of MIT courses, visit
MIT OpenCourseWare at

8
00:00:19,790 --> 00:00:21,040
ocw.mit.edu.

9
00:00:21,040 --> 00:00:22,660

10
00:00:22,660 --> 00:00:25,790
PROFESSOR: Good morning,
everybody.

11
00:00:25,790 --> 00:00:30,970
All right, I ended up the last
lecture talking about how to

12
00:00:30,970 --> 00:00:34,510
calculate the absolute
goodness of fit using

13
00:00:34,510 --> 00:00:36,763
something called the coefficient
of determination.

14
00:00:36,763 --> 00:00:39,390

15
00:00:39,390 --> 00:00:43,115
It's usually spelled as
R-squared, or R2.

16
00:00:43,115 --> 00:00:46,830

17
00:00:46,830 --> 00:00:49,070
And the formula was
quite simple.

18
00:00:49,070 --> 00:00:59,930

19
00:00:59,930 --> 00:01:04,269
We measure the goodness of the
fit as R-squared equals 1

20
00:01:04,269 --> 00:01:10,790
minus the estimated
error divided by

21
00:01:10,790 --> 00:01:12,490
the measured variance.

22
00:01:12,490 --> 00:01:16,170

23
00:01:16,170 --> 00:01:22,590
As I observed, R-squared always
lies between 0 and 1.

24
00:01:22,590 --> 00:01:27,140
If R-squared equals 1, that
means that the model that we

25
00:01:27,140 --> 00:01:32,370
constructed, the predicted
values if you will, explains

26
00:01:32,370 --> 00:01:37,260
all of the variability in the
data so that any change in the

27
00:01:37,260 --> 00:01:41,030
data is explained perfectly
by the model.

28
00:01:41,030 --> 00:01:42,910
We don't usually get 1.

29
00:01:42,910 --> 00:01:44,680
In fact, if I ever got
1, I would think

30
00:01:44,680 --> 00:01:45,930
somebody cheated me.

31
00:01:45,930 --> 00:01:48,760

32
00:01:48,760 --> 00:01:52,730
R-squared equals 0, or
conversely, it means there's

33
00:01:52,730 --> 00:01:56,730
no linear relationship at all
between the values predicted

34
00:01:56,730 --> 00:01:59,310
by the model and the
actual data.

35
00:01:59,310 --> 00:02:01,675
That is to say, the model
is totally worthless.

36
00:02:01,675 --> 00:02:05,360

37
00:02:05,360 --> 00:02:10,669
So we have code here, the top
of the screen, showing how

38
00:02:10,669 --> 00:02:13,500
easy it is to compute
R-squared.

39
00:02:13,500 --> 00:02:16,190
And for those of you who have a
little trouble interpreting

40
00:02:16,190 --> 00:02:19,560
the formula, because maybe
you're not quite sure what EE

41
00:02:19,560 --> 00:02:24,640
and MV mean, this will give you
a very straightforward way

42
00:02:24,640 --> 00:02:26,390
to understand it.

43
00:02:26,390 --> 00:02:30,310

44
00:02:30,310 --> 00:02:33,070
So now, we can run it.

45
00:02:33,070 --> 00:02:35,780
We can get some answers.

46
00:02:35,780 --> 00:02:38,240
So if we look at it, you'll
remember last time, we looked

47
00:02:38,240 --> 00:02:40,230
at two different fits.

48
00:02:40,230 --> 00:02:44,470
We looked at a quadratic fit
and a linear fit for the

49
00:02:44,470 --> 00:02:49,770
trajectory of an arrow
fired from my bow.

50
00:02:49,770 --> 00:02:51,585
And we can now compare
the two.

51
00:02:51,585 --> 00:02:56,690

52
00:02:56,690 --> 00:03:01,500
And not surprisingly, given what
we know about the physics

53
00:03:01,500 --> 00:03:06,560
of projectiles, we see it is
exactly what we'd expect, that

54
00:03:06,560 --> 00:03:14,000
the linear fit has an R-quared
of 0.0177, showing that, in

55
00:03:14,000 --> 00:03:17,530
fact, it explains almost
none of the data.

56
00:03:17,530 --> 00:03:22,070
Whereas the quadratic fit has
a really astonishingly good

57
00:03:22,070 --> 00:03:28,130
R-squared of 0.98, saying that
almost all of the changes in

58
00:03:28,130 --> 00:03:31,460
the values of the variables,
that is to say the way the y

59
00:03:31,460 --> 00:03:35,840
value changes with respect
to the x value, is

60
00:03:35,840 --> 00:03:38,150
explained by the model.

61
00:03:38,150 --> 00:03:41,460
i.e., we have a really
good model of

62
00:03:41,460 --> 00:03:44,750
the physical situation.

63
00:03:44,750 --> 00:03:46,000
Very comforting.

64
00:03:46,000 --> 00:03:48,250

65
00:03:48,250 --> 00:03:51,000
Essentially, it's telling us
at less than 2% of the

66
00:03:51,000 --> 00:03:56,800
variation is explained by the
linear model, 98% by the

67
00:03:56,800 --> 00:03:58,180
quadratic model.

68
00:03:58,180 --> 00:04:04,200
Presumably the other 2%
is experimental error.

69
00:04:04,200 --> 00:04:07,090
Well, now that we know that we
have a really good model of

70
00:04:07,090 --> 00:04:13,830
the data, we can ask the
question, why do we care?

71
00:04:13,830 --> 00:04:16,290
We have the data itself.

72
00:04:16,290 --> 00:04:19,320
What's the point of building
a model of the data?

73
00:04:19,320 --> 00:04:21,180
And that, of course, is what
we're getting when we run

74
00:04:21,180 --> 00:04:25,610
polyfit to get this curve.

75
00:04:25,610 --> 00:04:29,160
The whole purpose of creating
a model, or an important

76
00:04:29,160 --> 00:04:32,930
purpose of creating a model,
is to be able to answer

77
00:04:32,930 --> 00:04:37,290
questions about the actual
physical situation.

78
00:04:37,290 --> 00:04:40,200
So one of the questions one
might ask, for example, about

79
00:04:40,200 --> 00:04:43,010
firing an arrow is, how
fast is it going?

80
00:04:43,010 --> 00:04:46,180

81
00:04:46,180 --> 00:04:48,610
That's kind of a useful thing
to know if you're worried

82
00:04:48,610 --> 00:04:51,820
about whether it will penetrate
a target and kill

83
00:04:51,820 --> 00:04:55,380
somebody on the other
side, for example.

84
00:04:55,380 --> 00:04:58,000
We can't answer that
question directly

85
00:04:58,000 --> 00:05:00,350
looking at the data points.

86
00:05:00,350 --> 00:05:01,380
You look at the data.

87
00:05:01,380 --> 00:05:04,240
Well, I don't know.

88
00:05:04,240 --> 00:05:08,000
But we can use the model
to answer the question.

89
00:05:08,000 --> 00:05:11,970
And that's an exercise I want to
go through now to show you

90
00:05:11,970 --> 00:05:17,020
the interplay between models,
and theory, and computation,

91
00:05:17,020 --> 00:05:21,720
and how we can use the three to
answer relevant questions

92
00:05:21,720 --> 00:05:24,290
about data.

93
00:05:24,290 --> 00:05:26,790
No, I do not want to check for
new software, thank you.

94
00:05:26,790 --> 00:05:31,430
In fact, let's make sure it
won't do that anymore.

95
00:05:31,430 --> 00:05:36,650

96
00:05:36,650 --> 00:05:39,120
So let's look at
the PowerPoint.

97
00:05:39,120 --> 00:05:43,340
So here, we'll see how I'm using
a little bit of theory,

98
00:05:43,340 --> 00:05:48,100
not very much, to be able to
understand how to use the

99
00:05:48,100 --> 00:05:52,250
model to compute the
speed of the arrow.

100
00:05:52,250 --> 00:05:58,830
So what we see is we know by
our model, and by the good

101
00:05:58,830 --> 00:06:04,050
fit, that the trajectory is
given by y equals ax-squared

102
00:06:04,050 --> 00:06:06,900
plus bx plus c.

103
00:06:06,900 --> 00:06:08,150
We know that.

104
00:06:08,150 --> 00:06:10,160

105
00:06:10,160 --> 00:06:15,690
We also know from looking at
this equation that the highest

106
00:06:15,690 --> 00:06:23,720
point, which I'll call yPeak,
of the arrow must occur at

107
00:06:23,720 --> 00:06:28,340
xMid, the middle
of the x-axis.

108
00:06:28,340 --> 00:06:31,850
So if we look at a parabola, and
it doesn't matter what the

109
00:06:31,850 --> 00:06:38,240
parabola is, we always know
that the vertical peak is

110
00:06:38,240 --> 00:06:42,210
halfway along the x-axis.

111
00:06:42,210 --> 00:06:43,980
The math tells us that
from the equation.

112
00:06:43,980 --> 00:06:47,150

113
00:06:47,150 --> 00:06:52,640
So we can say yPeak is x times
xMid squared plus b

114
00:06:52,640 --> 00:06:54,880
times xMid plus c.

115
00:06:54,880 --> 00:06:58,410
So now, we have a model that
we can tell how high

116
00:06:58,410 --> 00:07:01,530
the arrow can get.

117
00:07:01,530 --> 00:07:09,020
The next question I'll ask is
if I fired the arrow from

118
00:07:09,020 --> 00:07:12,200
here, and it hits the
target here--

119
00:07:12,200 --> 00:07:14,410
I've exaggerated
by it this way.

120
00:07:14,410 --> 00:07:17,020
It's nowhere near this steep.

121
00:07:17,020 --> 00:07:21,150
How long does it take to
get from here to here?

122
00:07:21,150 --> 00:07:26,590
We don't have anything about
time in our data.

123
00:07:26,590 --> 00:07:31,660
Yet, I claim we have enough
information to go from the

124
00:07:31,660 --> 00:07:36,870
distance here and the distance
here to how long it's going to

125
00:07:36,870 --> 00:07:38,810
take the arrow to get from
here to the target.

126
00:07:38,810 --> 00:07:41,310

127
00:07:41,310 --> 00:07:42,560
Why do I know that?

128
00:07:42,560 --> 00:07:46,220

129
00:07:46,220 --> 00:07:49,240
What determines how long it's
going to take to get

130
00:07:49,240 --> 00:07:50,490
from here to here?

131
00:07:50,490 --> 00:07:53,310

132
00:07:53,310 --> 00:07:57,990
It's going to be how long it
takes it to fall that far.

133
00:07:57,990 --> 00:08:01,040
It's going to be gravity.

134
00:08:01,040 --> 00:08:05,520
Because we know that gravity, at
least on this planet, is a

135
00:08:05,520 --> 00:08:08,035
constant or close
enough to it.

136
00:08:08,035 --> 00:08:12,370
Unless maybe the arrow were
going a million miles.

137
00:08:12,370 --> 00:08:15,930
And it's going to be gravity
that tells me how long it

138
00:08:15,930 --> 00:08:17,290
takes to get from
here to here.

139
00:08:17,290 --> 00:08:20,250

140
00:08:20,250 --> 00:08:27,540
And when it gets to the bottom,
it's going to be here,

141
00:08:27,540 --> 00:08:34,270
So again, I can use some very
simple math and say that the

142
00:08:34,270 --> 00:08:40,100
time will be the square root of
2 times the yPeak divided

143
00:08:40,100 --> 00:08:41,475
by the gravitational constant.

144
00:08:41,475 --> 00:08:46,680

145
00:08:46,680 --> 00:08:49,540
Because I know that however long
it takes to get from this

146
00:08:49,540 --> 00:08:52,990
height to this height is going
to be the same time it takes

147
00:08:52,990 --> 00:08:54,650
to get from this point
to this point.

148
00:08:54,650 --> 00:08:57,620

149
00:08:57,620 --> 00:09:00,800
And that will therefore let me
compute the average speed from

150
00:09:00,800 --> 00:09:03,100
here to here.

151
00:09:03,100 --> 00:09:07,810
And once I know that,
I'm done.

152
00:09:07,810 --> 00:09:11,860
Now again, this is assuming no
drag and things like that.

153
00:09:11,860 --> 00:09:15,650
The thing that we always have to
understand about a model is

154
00:09:15,650 --> 00:09:20,360
no model is actually
ever correct.

155
00:09:20,360 --> 00:09:24,250
On the other hand, many models
are very useful and they're

156
00:09:24,250 --> 00:09:26,570
close enough to correct.

157
00:09:26,570 --> 00:09:30,190
So I left out things like
gravity, wind shear

158
00:09:30,190 --> 00:09:31,440
and stuff like that.

159
00:09:31,440 --> 00:09:35,030
But in fact, the answer we get
here will turn out to be very

160
00:09:35,030 --> 00:09:37,590
close to correct.

161
00:09:37,590 --> 00:09:40,605
We can now go back and
look at some code.

162
00:09:40,605 --> 00:09:48,700

163
00:09:48,700 --> 00:09:49,950
Get rid of this.

164
00:09:49,950 --> 00:09:58,300

165
00:09:58,300 --> 00:10:00,200
And so now, you'll see
this on the handout.

166
00:10:00,200 --> 00:10:04,390

167
00:10:04,390 --> 00:10:09,820
I'm going to just write a little
bit of code that just

168
00:10:09,820 --> 00:10:14,310
goes through the math I just
showed you to compute the

169
00:10:14,310 --> 00:10:17,970
average x velocity.

170
00:10:17,970 --> 00:10:20,180
Got a print statement here
I use to debug it.

171
00:10:20,180 --> 00:10:21,430
And I'm going to return it.

172
00:10:21,430 --> 00:10:25,500

173
00:10:25,500 --> 00:10:28,935
And then, we'll just be able to
run it and see what we get.

174
00:10:28,935 --> 00:10:41,120

175
00:10:41,120 --> 00:10:43,526
Well, all right, that
we looked at before.

176
00:10:43,526 --> 00:10:49,310

177
00:10:49,310 --> 00:10:51,160
I forgot to close the
previous figure.

178
00:10:51,160 --> 00:10:54,900
So now, I'm sure this is a
problem you've all seen.

179
00:10:54,900 --> 00:10:56,720
And we'll fix it the
way we always fix

180
00:10:56,720 --> 00:10:58,025
things, just start over.

181
00:10:58,025 --> 00:11:13,920

182
00:11:13,920 --> 00:11:17,220
I'll bet you guys have also
seen this happen.

183
00:11:17,220 --> 00:11:21,730
What this is suggesting, as
we've seen before, is that the

184
00:11:21,730 --> 00:11:26,220
process, the old process,
still exists.

185
00:11:26,220 --> 00:11:28,790
Not a good thing.

186
00:11:28,790 --> 00:11:30,500
Again, I'm sure you've
all seen these.

187
00:11:30,500 --> 00:11:32,560
Let's make sure we don't have
anything running here that

188
00:11:32,560 --> 00:11:34,300
looks like IDLE.

189
00:11:34,300 --> 00:11:35,550
We don't.

190
00:11:35,550 --> 00:11:42,790

191
00:11:42,790 --> 00:11:44,310
Just takes it a little time.

192
00:11:44,310 --> 00:11:46,560
There it is, all right.

193
00:11:46,560 --> 00:11:47,810
All right, now we'll go back.

194
00:11:47,810 --> 00:11:53,520

195
00:11:53,520 --> 00:11:57,790
All of this happened because I
forgot to close the figure and

196
00:11:57,790 --> 00:12:01,360
executed pyLab.show twice,
which we know

197
00:12:01,360 --> 00:12:02,755
can lead to bad things.

198
00:12:02,755 --> 00:12:05,800

199
00:12:05,800 --> 00:12:08,430
So let's get rid of this.

200
00:12:08,430 --> 00:12:14,420

201
00:12:14,420 --> 00:12:15,670
Now, we'll run it.

202
00:12:15,670 --> 00:12:23,590

203
00:12:23,590 --> 00:12:32,600
And now, we have our figure just
using the quadratic fit.

204
00:12:32,600 --> 00:12:37,370
And we see that the speed is
136.25 feet per second.

205
00:12:37,370 --> 00:12:39,980
Do I believe 136.25?

206
00:12:39,980 --> 00:12:41,520
Not really.

207
00:12:41,520 --> 00:12:43,400
I know it's the ballpark.

208
00:12:43,400 --> 00:12:47,850
I confused precision with
accuracy here by giving you it

209
00:12:47,850 --> 00:12:50,000
to two decimal places.

210
00:12:50,000 --> 00:12:52,300
I can compute it as precisely
as I want.

211
00:12:52,300 --> 00:12:55,050
But that doesn't mean it's
actually accurate.

212
00:12:55,050 --> 00:12:58,970
Probably, I should have just
said it's about 135 or

213
00:12:58,970 --> 00:13:00,230
something like that.

214
00:13:00,230 --> 00:13:02,150
But it's pretty good.

215
00:13:02,150 --> 00:13:04,910
And for those of who don't know
how to do this arithmetic

216
00:13:04,910 --> 00:13:10,190
in your head like me, this is
about 93 miles per hour.

217
00:13:10,190 --> 00:13:13,840
And for comparison, the speed of
sound, instead of 136 feet

218
00:13:13,840 --> 00:13:16,650
per second, is 1,100
feet per second.

219
00:13:16,650 --> 00:13:19,380
So it's traveling pretty fast.

220
00:13:19,380 --> 00:13:20,990
Well, what's the
point of this?

221
00:13:20,990 --> 00:13:22,490
I don't really care
if you know how

222
00:13:22,490 --> 00:13:24,550
fast an arrow travels.

223
00:13:24,550 --> 00:13:28,540
I don't expect you'll ever
need to compute that.

224
00:13:28,540 --> 00:13:32,670
But I wanted to show you this
as an example of a pattern

225
00:13:32,670 --> 00:13:35,510
that we use a lot.

226
00:13:35,510 --> 00:13:39,495
So what we did is we started
with an experiment.

227
00:13:39,495 --> 00:13:44,750

228
00:13:44,750 --> 00:13:48,580
You didn't see this, but I
actually stood in my backyard

229
00:13:48,580 --> 00:13:53,300
and shot a bunch of arrows and
measured them, got real data

230
00:13:53,300 --> 00:13:54,580
out of that.

231
00:13:54,580 --> 00:13:57,790
And this gave me some data
about the behavior of a

232
00:13:57,790 --> 00:13:59,040
physical system.

233
00:13:59,040 --> 00:14:05,590

234
00:14:05,590 --> 00:14:07,010
That's what I get for
wearing a tie.

235
00:14:07,010 --> 00:14:10,930
Maybe it'll be quieter if
I put it in my shirt.

236
00:14:10,930 --> 00:14:13,490
Actually, it looks silly.

237
00:14:13,490 --> 00:14:14,540
Excuse me.

238
00:14:14,540 --> 00:14:16,875
I hope none of you will mind
if I take my tie off?

239
00:14:16,875 --> 00:14:19,845
It seems to be making noises
in the microphone.

240
00:14:19,845 --> 00:14:27,680

241
00:14:27,680 --> 00:14:29,306
Maybe we should write
a computation.

242
00:14:29,306 --> 00:14:32,220

243
00:14:32,220 --> 00:14:36,160
All right, so ends my
experiment with

244
00:14:36,160 --> 00:14:39,070
trying to look dignified.

245
00:14:39,070 --> 00:14:40,420
Not something I'm good at.

246
00:14:40,420 --> 00:14:44,740

247
00:14:44,740 --> 00:14:47,740
OK, had an experiment.

248
00:14:47,740 --> 00:14:50,110
That gave us some data.

249
00:14:50,110 --> 00:15:05,170
We then use computation to both
find and very importantly

250
00:15:05,170 --> 00:15:09,160
evaluate a model.

251
00:15:09,160 --> 00:15:10,800
It's no good just to
find the model.

252
00:15:10,800 --> 00:15:14,350
You need to do some evaluation
to convince yourself that it's

253
00:15:14,350 --> 00:15:24,730
a good model of the actual
physical system.

254
00:15:24,730 --> 00:15:43,450
And then, finally, we use some
theory and analysis and

255
00:15:43,450 --> 00:15:54,975
computation to derive the
consequence of the model.

256
00:15:54,975 --> 00:16:06,600

257
00:16:06,600 --> 00:16:10,140
And then, since we believe the
accuracy of the model, we

258
00:16:10,140 --> 00:16:13,630
assume this consequence was
also a true fact about the

259
00:16:13,630 --> 00:16:16,700
physical system we
started with.

260
00:16:16,700 --> 00:16:20,840
This is a pattern that we see
over and over again these days

261
00:16:20,840 --> 00:16:23,600
in all branches of science
and engineering.

262
00:16:23,600 --> 00:16:25,630
And it's just the kind
of thing that you

263
00:16:25,630 --> 00:16:27,260
should get used to doing.

264
00:16:27,260 --> 00:16:30,710
It is what you will do if you go
onto a career in science or

265
00:16:30,710 --> 00:16:32,780
engineering.

266
00:16:32,780 --> 00:16:37,580
OK, that's all I want to say
now about the topic of data

267
00:16:37,580 --> 00:16:40,210
and experiments and analysis.

268
00:16:40,210 --> 00:16:44,600
We will return to this topic
of interpretation of data

269
00:16:44,600 --> 00:16:48,260
later in the semester near the
end when we start talking

270
00:16:48,260 --> 00:16:51,180
about machine learning
and clustering.

271
00:16:51,180 --> 00:16:56,910
But for now, I want to pull
back and start down a new

272
00:16:56,910 --> 00:17:01,340
track that will, I'm sure you'll
be pleased to hear,

273
00:17:01,340 --> 00:17:05,420
dovetail nicely with the next
few problem sets that you're

274
00:17:05,420 --> 00:17:08,050
going to have to work on.

275
00:17:08,050 --> 00:17:12,032
What I want to talk about is
the topic of optimization.

276
00:17:12,032 --> 00:17:23,069

277
00:17:23,069 --> 00:17:27,099
Not so much optimization in the
sense of how do you make a

278
00:17:27,099 --> 00:17:31,230
program fast, though we will
talk a little about that, but

279
00:17:31,230 --> 00:17:33,880
what people refer to as
optimization problems.

280
00:17:33,880 --> 00:17:37,710

281
00:17:37,710 --> 00:17:42,210
How do we write programs to
find optimal solutions to

282
00:17:42,210 --> 00:17:43,830
problems that occur
in real life?

283
00:17:43,830 --> 00:17:46,830

284
00:17:46,830 --> 00:17:50,740
Every optimization problem
we'll look at is

285
00:17:50,740 --> 00:17:52,450
going to have two parts.

286
00:17:52,450 --> 00:17:55,360

287
00:17:55,360 --> 00:18:07,390
There's going to be (1) an
objective function that will

288
00:18:07,390 --> 00:18:11,180
either be maximized
or minimized.

289
00:18:11,180 --> 00:18:15,210
So for example, I might want to
find the minimal air fare

290
00:18:15,210 --> 00:18:18,860
between Boston and Istanbul.

291
00:18:18,860 --> 00:18:21,560
Or more likely, the minimum
bus fare between

292
00:18:21,560 --> 00:18:24,290
Boston and New York.

293
00:18:24,290 --> 00:18:27,070
So there's an objective
function.

294
00:18:27,070 --> 00:18:28,750
Sometimes, you find the least.

295
00:18:28,750 --> 00:18:30,960
Sometimes, you find the most.

296
00:18:30,960 --> 00:18:35,660
Maybe I want to maximize
my income.

297
00:18:35,660 --> 00:18:43,600
And (2) a set of constraints
that have to be satisfied.

298
00:18:43,600 --> 00:18:50,210

299
00:18:50,210 --> 00:18:54,210
So maybe I want to find the
minimum transportation,

300
00:18:54,210 --> 00:18:59,190
minimum cost transportation
between Boston and New York

301
00:18:59,190 --> 00:19:02,200
subject to the constraint that
it not take more than eight

302
00:19:02,200 --> 00:19:06,630
hours or some such thing.

303
00:19:06,630 --> 00:19:09,630
So the objective function that
you're minimizing or

304
00:19:09,630 --> 00:19:13,760
maximizing, and some
set of constraints

305
00:19:13,760 --> 00:19:16,910
that must be obeyed.

306
00:19:16,910 --> 00:19:21,170
A vast number of problems of
practical importance can be

307
00:19:21,170 --> 00:19:23,580
formulated this way.

308
00:19:23,580 --> 00:19:28,050
Once we've formulated in this
systematic way, we can then

309
00:19:28,050 --> 00:19:31,830
think about how to attack them
with a computation that will

310
00:19:31,830 --> 00:19:33,620
help us solve the problem.

311
00:19:33,620 --> 00:19:36,470

312
00:19:36,470 --> 00:19:38,640
You guys do this all the time.

313
00:19:38,640 --> 00:19:42,500
I heard a talk yesterday by
Jeremy Wertheimer, an MIT

314
00:19:42,500 --> 00:19:45,810
graduate, who founded a
company called ITA.

315
00:19:45,810 --> 00:19:49,660
If you ever use Kayak, for
example, or many of these

316
00:19:49,660 --> 00:19:52,840
systems to find an airline
fare, they use some of

317
00:19:52,840 --> 00:19:57,180
Jeremy's code and algorithms
to solve these various

318
00:19:57,180 --> 00:19:59,720
optimization problems
like this.

319
00:19:59,720 --> 00:20:03,600
If you've ever used Google or
Bing, they solve optimization

320
00:20:03,600 --> 00:20:06,480
problems to decide what
pages to show you.

321
00:20:06,480 --> 00:20:08,550
They're all over the place.

322
00:20:08,550 --> 00:20:12,760
There are a lot of classic
optimization problems that

323
00:20:12,760 --> 00:20:17,700
people have worked
on for decades.

324
00:20:17,700 --> 00:20:20,640
What we often do when confronted
with a new problem,

325
00:20:20,640 --> 00:20:23,620
and it's something you'll get
some experience on in problem

326
00:20:23,620 --> 00:20:30,680
sets, is take a seemingly new
problem and map it onto a

327
00:20:30,680 --> 00:20:35,490
classic problem, and then use
one of the classic solutions.

328
00:20:35,490 --> 00:20:39,100
So we'll go through this
section of the course.

329
00:20:39,100 --> 00:20:43,990
And we'll look at a number of
classic optimization problems.

330
00:20:43,990 --> 00:20:47,430
And then, you can think about
how you would map other

331
00:20:47,430 --> 00:20:48,835
problems onto those.

332
00:20:48,835 --> 00:20:53,230

333
00:20:53,230 --> 00:21:04,230
This is the process known as
problem reduction, where we

334
00:21:04,230 --> 00:21:09,970
take a problem and map it onto
an existing problem that we

335
00:21:09,970 --> 00:21:12,590
already know how to solve.

336
00:21:12,590 --> 00:21:15,570
I'm not going to go through a
list of classic optimization

337
00:21:15,570 --> 00:21:16,960
problems right now.

338
00:21:16,960 --> 00:21:20,055
But we'll see a bunch of
them as we go forward.

339
00:21:20,055 --> 00:21:22,640

340
00:21:22,640 --> 00:21:25,310
Now, an important thing to
think about when we think

341
00:21:25,310 --> 00:21:29,750
about optimization problems
is how long, how

342
00:21:29,750 --> 00:21:32,210
hard, they are to solve.

343
00:21:32,210 --> 00:21:36,450
So far, we have looked at
problems that, for the most

344
00:21:36,450 --> 00:21:42,600
part, have pretty fast
solutions, often sub-linear,

345
00:21:42,600 --> 00:21:46,990
binary search, sometimes linear,
and at worst case,

346
00:21:46,990 --> 00:21:48,260
low-order polynomials.

347
00:21:48,260 --> 00:21:52,890

348
00:21:52,890 --> 00:21:57,130
Optimization problems, as we'll
see, are typically much

349
00:21:57,130 --> 00:21:59,440
worse than that.

350
00:21:59,440 --> 00:22:04,070
In fact, what we'll see
is there is often no

351
00:22:04,070 --> 00:22:07,980
computationally efficient
way to solve them.

352
00:22:07,980 --> 00:22:12,610
And so we end up dealing with
approximate solutions to them,

353
00:22:12,610 --> 00:22:16,290
or what people might call
best effort solutions.

354
00:22:16,290 --> 00:22:18,460
And we see that as
an increasing

355
00:22:18,460 --> 00:22:22,230
trend in tackling problems.

356
00:22:22,230 --> 00:22:26,210
All right, enough of this
abstract stuff.

357
00:22:26,210 --> 00:22:27,980
Let's look at an example.

358
00:22:27,980 --> 00:22:31,950
So one of the classic
optimization problems is

359
00:22:31,950 --> 00:22:35,440
called the knapsack problem.

360
00:22:35,440 --> 00:22:37,110
People know what
a knapsack is?

361
00:22:37,110 --> 00:22:39,070
Sort of an archaic term.

362
00:22:39,070 --> 00:22:43,020
Today, people would use
the word backpack.

363
00:22:43,020 --> 00:22:46,300
But in the old days, they called
them knapsacks when

364
00:22:46,300 --> 00:22:48,650
they started looking
at these things.

365
00:22:48,650 --> 00:22:52,160
And the problem is also
discussed in the context of a

366
00:22:52,160 --> 00:22:56,550
burglar or various
kinds of thieves.

367
00:22:56,550 --> 00:22:58,730
So it's not easy being a
burglar, by the way.

368
00:22:58,730 --> 00:23:01,360
I don't know if any of
you ever tried it.

369
00:23:01,360 --> 00:23:04,160
You've got some of the obvious
problems, like making sure the

370
00:23:04,160 --> 00:23:06,260
house is empty and
picking locks,

371
00:23:06,260 --> 00:23:08,800
circumventing alarms, et cetera.

372
00:23:08,800 --> 00:23:11,690
But one of the really hard
problems a burglar has to deal

373
00:23:11,690 --> 00:23:14,610
with is deciding
what to steal.

374
00:23:14,610 --> 00:23:17,880
Because you break into the
typical luxury home-- and why

375
00:23:17,880 --> 00:23:19,660
would you break into a
poor person's house

376
00:23:19,660 --> 00:23:21,730
if you were a burglar--

377
00:23:21,730 --> 00:23:26,090
there's usually far more to
steal than you can carry away.

378
00:23:26,090 --> 00:23:28,750
And so the problem is formulated
in terms of the

379
00:23:28,750 --> 00:23:30,860
burglar having a backpack.

380
00:23:30,860 --> 00:23:33,510
They can put a certain amount
of stuff in it.

381
00:23:33,510 --> 00:23:40,090
And they have to maximize the
value of what they steal

382
00:23:40,090 --> 00:23:43,940
subject to the constraint of
how much weight they can

383
00:23:43,940 --> 00:23:46,330
actually carry.

384
00:23:46,330 --> 00:23:49,180
So it's a classic optimization
problem.

385
00:23:49,180 --> 00:23:53,020
And people have worked for years
at how to solve it, not

386
00:23:53,020 --> 00:23:54,780
so much because they want
to be burglars.

387
00:23:54,780 --> 00:23:58,000
But as you'll see, these kinds
of optimization problems are

388
00:23:58,000 --> 00:24:00,490
actually quite common.

389
00:24:00,490 --> 00:24:03,420
So let's look at an example.

390
00:24:03,420 --> 00:24:04,800
You break into the house.

391
00:24:04,800 --> 00:24:07,360
And among other things,
you have a

392
00:24:07,360 --> 00:24:08,850
choice of what to steal.

393
00:24:08,850 --> 00:24:13,090
You have a rather strange
looking clock, some artwork, a

394
00:24:13,090 --> 00:24:18,580
book, a Velvet Elvis in case
you lean in that direction,

395
00:24:18,580 --> 00:24:20,630
all sorts of things.

396
00:24:20,630 --> 00:24:25,380
And for some reason, the owner
was nice enough to leave you

397
00:24:25,380 --> 00:24:29,200
information about how much
everything cost and how much

398
00:24:29,200 --> 00:24:30,350
it weighed.

399
00:24:30,350 --> 00:24:32,760
So you find this
piece of paper.

400
00:24:32,760 --> 00:24:35,920
And now, you're trying to decide
what to steal based

401
00:24:35,920 --> 00:24:39,120
upon this in a way to
maximize your value.

402
00:24:39,120 --> 00:24:42,030

403
00:24:42,030 --> 00:24:44,590
How do we go about doing it?

404
00:24:44,590 --> 00:24:46,580
Oh, I should show
you, by the way.

405
00:24:46,580 --> 00:24:48,360
There's a picture of
a typical knapsack.

406
00:24:48,360 --> 00:24:52,260

407
00:24:52,260 --> 00:24:56,600
All right, it's almost
Easter, after all.

408
00:24:56,600 --> 00:25:02,125
Well, the simplest solution is
probably a greedy algorithm.

409
00:25:02,125 --> 00:25:06,430

410
00:25:06,430 --> 00:25:10,440
And we'll talk a lot about
greedy algorithms because they

411
00:25:10,440 --> 00:25:15,630
are very popular and often
the right way to

412
00:25:15,630 --> 00:25:20,640
tackle a hard problem.

413
00:25:20,640 --> 00:25:26,650
So the notion of a greedy
algorithm is it's iterative.

414
00:25:26,650 --> 00:25:30,646
And at each step, you pick the
locally optimal solution.

415
00:25:30,646 --> 00:25:57,780

416
00:25:57,780 --> 00:26:03,610
So you make the best choice, put
that item in the knapsack.

417
00:26:03,610 --> 00:26:05,810
Ask if you have room, if
you're out of weight.

418
00:26:05,810 --> 00:26:09,620
If not, you make the best choice
of the remaining ones.

419
00:26:09,620 --> 00:26:10,700
Ask the same question.

420
00:26:10,700 --> 00:26:16,540
You do that until you can't
fit anything else in.

421
00:26:16,540 --> 00:26:22,850
Now of course, to do that, that
assumes that we know at

422
00:26:22,850 --> 00:26:28,380
each stage what we mean
by locally optimal.

423
00:26:28,380 --> 00:26:31,130
And of course, we have
choices here.

424
00:26:31,130 --> 00:26:36,000
We're trying to figure out,
in some sense, what greedy

425
00:26:36,000 --> 00:26:38,890
algorithm, what approach to
being greedy, will give us the

426
00:26:38,890 --> 00:26:40,940
best result.

427
00:26:40,940 --> 00:26:43,900
So one could, for example,
say, all right.

428
00:26:43,900 --> 00:26:46,760
At each step, I'll choose the
most valuable item and put

429
00:26:46,760 --> 00:26:48,910
that in my knapsack.

430
00:26:48,910 --> 00:26:53,490
And I'll do that till I run
out of valuable items.

431
00:26:53,490 --> 00:26:57,890
Or, you could, at each step,
say, well, what I'm really

432
00:26:57,890 --> 00:27:01,670
going to choose is the one
that weights the least.

433
00:27:01,670 --> 00:27:03,290
That will give me
the most items.

434
00:27:03,290 --> 00:27:04,920
And maybe that will give
me the most total

435
00:27:04,920 --> 00:27:07,210
value when I'm done.

436
00:27:07,210 --> 00:27:10,810
Or maybe, at each step, you
could say, well, let me choose

437
00:27:10,810 --> 00:27:14,610
the one that has the best
value to weight ratio

438
00:27:14,610 --> 00:27:15,410
and put that in.

439
00:27:15,410 --> 00:27:20,100
And maybe that will give
me the best solution.

440
00:27:20,100 --> 00:27:26,080
As we will see, in this case,
none of those is guaranteed to

441
00:27:26,080 --> 00:27:30,090
give you the best solution
all the time.

442
00:27:30,090 --> 00:27:33,390
In fact, as we'll see, none of
them is guaranteed to be

443
00:27:33,390 --> 00:27:37,430
better than any of the
others all the time.

444
00:27:37,430 --> 00:27:41,790
And that's one of the issues
with greedy algorithms.

445
00:27:41,790 --> 00:27:45,340
I should point out, by the way,
that this version of the

446
00:27:45,340 --> 00:27:49,620
knapsack problem that we're
talking about is typically

447
00:27:49,620 --> 00:27:51,825
called the 0/1 knapsack
problem.

448
00:27:51,825 --> 00:27:59,180

449
00:27:59,180 --> 00:28:04,840
And that's because we either
have to take the entire item

450
00:28:04,840 --> 00:28:07,480
or none of the item.

451
00:28:07,480 --> 00:28:10,270
We're not allowed to cut the
Velvet Elvis in half and take

452
00:28:10,270 --> 00:28:11,520
half of it.

453
00:28:11,520 --> 00:28:14,120

454
00:28:14,120 --> 00:28:18,300
This is in contrast to the
continuous knapsack problem.

455
00:28:18,300 --> 00:28:21,300
If you imagine you break into
the house and you see a barrel

456
00:28:21,300 --> 00:28:26,840
of gold dust, and a barrel of
silver dust, and a barrel of

457
00:28:26,840 --> 00:28:31,500
raisins, what you would do is
you would fill your knapsack

458
00:28:31,500 --> 00:28:34,380
with as much gold as you
could carry, or until

459
00:28:34,380 --> 00:28:36,540
you ran out of gold.

460
00:28:36,540 --> 00:28:38,480
And then, you would fill it
with as much silver as you

461
00:28:38,480 --> 00:28:39,730
could carry.

462
00:28:39,730 --> 00:28:41,000
And then, if there's
any room left,

463
00:28:41,000 --> 00:28:43,900
you'd put in the raisins.

464
00:28:43,900 --> 00:28:47,110
For the continuous knapsack
problem, a greedy algorithm

465
00:28:47,110 --> 00:28:50,470
provides an optimal solution.

466
00:28:50,470 --> 00:28:53,735
Unfortunately, most of the
problems we actually encounter

467
00:28:53,735 --> 00:28:58,560
in life, as we'll see, are
0/1 knapsack problems.

468
00:28:58,560 --> 00:29:01,160
You either take something
or you don't.

469
00:29:01,160 --> 00:29:03,910
And that's more complicated.

470
00:29:03,910 --> 00:29:05,220
All right, let's look
at some code.

471
00:29:05,220 --> 00:29:13,280

472
00:29:13,280 --> 00:29:15,900
So I'm going to formulate it.

473
00:29:15,900 --> 00:29:21,510
I'm first going to start by
putting in a class, just so

474
00:29:21,510 --> 00:29:24,110
the rest of my code
is simpler.

475
00:29:24,110 --> 00:29:26,200
This is something we've been
talking about, that

476
00:29:26,200 --> 00:29:29,960
increasingly people want to
start by putting in some

477
00:29:29,960 --> 00:29:32,190
useful data abstractions.

478
00:29:32,190 --> 00:29:37,030
So I've got a class item where
I can put in the item.

479
00:29:37,030 --> 00:29:38,170
I can get its name.

480
00:29:38,170 --> 00:29:39,120
I get its value.

481
00:29:39,120 --> 00:29:39,990
I can get its weight.

482
00:29:39,990 --> 00:29:41,860
And I can print it.

483
00:29:41,860 --> 00:29:48,130
Kind of a boring class,
but useful to have.

484
00:29:48,130 --> 00:29:56,220
Then, I'm going to use this
class to build items.

485
00:29:56,220 --> 00:29:59,040
And in this case, I'm going to
build the items based upon

486
00:29:59,040 --> 00:30:02,240
what we just looked at,
the table that--

487
00:30:02,240 --> 00:30:03,470
I think it's in your hand out.

488
00:30:03,470 --> 00:30:07,250
And it's also on this slide.

489
00:30:07,250 --> 00:30:10,520
Later, if we want, we can have
a randomized program to build

490
00:30:10,520 --> 00:30:13,250
up a much bigger choice
of items.

491
00:30:13,250 --> 00:30:15,450
But here, we'll just try the
clock, the painting, the

492
00:30:15,450 --> 00:30:19,350
radio, the vase, the book,
and the computer.

493
00:30:19,350 --> 00:30:20,765
Now comes the interesting
part.

494
00:30:20,765 --> 00:30:25,690

495
00:30:25,690 --> 00:30:28,970
I've written a function, greedy,
that takes three

496
00:30:28,970 --> 00:30:31,410
arguments--

497
00:30:31,410 --> 00:30:35,830
the set of items that I have to
choose from, makes sense,

498
00:30:35,830 --> 00:30:39,640
the maximum weight the
burglar can carry.

499
00:30:39,640 --> 00:30:43,580
And there's something called
key function, which is

500
00:30:43,580 --> 00:30:47,960
defining essentially what I
mean by locally optimal.

501
00:30:47,960 --> 00:30:55,340

502
00:30:55,340 --> 00:30:58,230
Then, it's quite simple.

503
00:30:58,230 --> 00:31:06,270
I'm going to sort the items
using the key function.

504
00:31:06,270 --> 00:31:09,190
Remember, sort has this optional
argument that says,

505
00:31:09,190 --> 00:31:10,670
what's the ordering?

506
00:31:10,670 --> 00:31:12,450
So maybe I'll order
it by value.

507
00:31:12,450 --> 00:31:13,870
Maybe I'll order
it by density.

508
00:31:13,870 --> 00:31:16,980
Maybe I'll order it by weight.

509
00:31:16,980 --> 00:31:20,900
I'm going to reverse it,
because I want the most

510
00:31:20,900 --> 00:31:25,890
valuable first, not the least
valuable, for example.

511
00:31:25,890 --> 00:31:29,510
And then, I'm going to just
take the first thing on my

512
00:31:29,510 --> 00:31:33,650
list until I run out of weight,
and then I'm done.

513
00:31:33,650 --> 00:31:36,105
And I'll return the result
and the total value.

514
00:31:36,105 --> 00:31:41,600

515
00:31:41,600 --> 00:31:45,310
To make life simple, I'm going
to define some functions.

516
00:31:45,310 --> 00:31:51,100
These are the functions that
I can use for the ordering.

517
00:31:51,100 --> 00:31:54,830
Value, which is just return
the value of the item.

518
00:31:54,830 --> 00:31:59,190
The inverse of the weight,
because I'm thinking, as a

519
00:31:59,190 --> 00:32:00,760
greedy algorithm, I'll take the

520
00:32:00,760 --> 00:32:02,950
lightest, not the heaviest.

521
00:32:02,950 --> 00:32:06,670
And since I'm reversing it,
I want to do the inverse.

522
00:32:06,670 --> 00:32:10,400
And the density, which
is just the value

523
00:32:10,400 --> 00:32:11,650
divided by the weight.

524
00:32:11,650 --> 00:32:15,380

525
00:32:15,380 --> 00:32:17,105
OK, make sense to everybody?

526
00:32:17,105 --> 00:32:20,790

527
00:32:20,790 --> 00:32:22,370
You with me?

528
00:32:22,370 --> 00:32:25,010
Speak now, or not.

529
00:32:25,010 --> 00:32:27,890
And then, we'll test it.

530
00:32:27,890 --> 00:32:31,520
So again, kind of a theme of
this part of the course.

531
00:32:31,520 --> 00:32:36,020
As we write these more complex
programs, we tend to have to

532
00:32:36,020 --> 00:32:38,320
worry about our test
harnesses.

533
00:32:38,320 --> 00:32:41,280
So I've got a function that
tests the greedy algorithm,

534
00:32:41,280 --> 00:32:44,590
and then another function that
tests all three greedy

535
00:32:44,590 --> 00:32:45,850
approaches--

536
00:32:45,850 --> 00:32:48,510
the one algorithm with
different functions--

537
00:32:48,510 --> 00:32:53,220
and looks at what
our results are.

538
00:32:53,220 --> 00:32:54,520
So let's run it.

539
00:32:54,520 --> 00:33:02,240

540
00:33:02,240 --> 00:33:04,020
See what we get.

541
00:33:04,020 --> 00:33:05,500
Oh, you know what I did?

542
00:33:05,500 --> 00:33:07,090
Just the same thing
I did last time.

543
00:33:07,090 --> 00:33:09,920
But this time, I'm going
to be smarter.

544
00:33:09,920 --> 00:33:14,810
We're going to get rid of this
figure and comment out the

545
00:33:14,810 --> 00:33:16,060
code that generated it.

546
00:33:16,060 --> 00:33:31,150

547
00:33:31,150 --> 00:33:32,810
And now, we'll test the
greedy algorithms.

548
00:33:32,810 --> 00:33:39,210

549
00:33:39,210 --> 00:33:43,570
So we see the items we had to
choose from, which I printed

550
00:33:43,570 --> 00:33:46,640
using the string function
and items.

551
00:33:46,640 --> 00:33:51,080
And if I use greedy by value to
fill a knapsack of size 20,

552
00:33:51,080 --> 00:33:56,290
we see that I end up getting
just the computer if I do

553
00:33:56,290 --> 00:33:59,490
greedy by value.

554
00:33:59,490 --> 00:34:03,860
This is for the nerd burglar.

555
00:34:03,860 --> 00:34:06,120
If I use weight, I
get a different--

556
00:34:06,120 --> 00:34:08,540
I get more things, not
surprisingly --

557
00:34:08,540 --> 00:34:12,429
but lower value.

558
00:34:12,429 --> 00:34:17,219
And if I use density, I also
get four things, but four

559
00:34:17,219 --> 00:34:19,720
different things, and I
get a higher value.

560
00:34:19,720 --> 00:34:23,139

561
00:34:23,139 --> 00:34:26,389
So I see that I can run these
greedy algorithms.

562
00:34:26,389 --> 00:34:27,969
I can get an answer.

563
00:34:27,969 --> 00:34:30,790
But it's not always
the same answer.

564
00:34:30,790 --> 00:34:35,520

565
00:34:35,520 --> 00:34:38,429
As I said earlier, greedy
by density happens

566
00:34:38,429 --> 00:34:40,170
to work best here.

567
00:34:40,170 --> 00:34:44,679
But you shouldn't assume that
will always be the case.

568
00:34:44,679 --> 00:34:47,130
I'm sure you can all imagine
a different assignment of

569
00:34:47,130 --> 00:34:50,159
weights and values that would
make greedy by density give

570
00:34:50,159 --> 00:34:53,710
you a bad answer.

571
00:34:53,710 --> 00:34:56,350
All right, before we
talk about how good

572
00:34:56,350 --> 00:34:58,200
these answers are--

573
00:34:58,200 --> 00:35:01,290
and we will come back to that
as, in particular, suppose I

574
00:35:01,290 --> 00:35:03,480
want the best answer--

575
00:35:03,480 --> 00:35:07,350
I want to stop for a minute and
talk about the algorithmic

576
00:35:07,350 --> 00:35:10,220
efficiency of the greedy
algorithm.

577
00:35:10,220 --> 00:35:13,130

578
00:35:13,130 --> 00:35:14,770
So let's go back and
look at the code.

579
00:35:14,770 --> 00:35:17,030
And this is why people use
greedy algorithms.

580
00:35:17,030 --> 00:35:19,290
Actually, there are
two reasons.

581
00:35:19,290 --> 00:35:23,390
One reason is that they're easy
to program, and that's

582
00:35:23,390 --> 00:35:25,420
always a good thing.

583
00:35:25,420 --> 00:35:31,140
And the other is that they are
typically highly efficient.

584
00:35:31,140 --> 00:35:34,740
So what's the efficiency
of this?

585
00:35:34,740 --> 00:35:36,750
How would we think about
the efficiency

586
00:35:36,750 --> 00:35:40,060
of this greedy algorithm?

587
00:35:40,060 --> 00:35:43,080
What are we looking at here?

588
00:35:43,080 --> 00:35:46,130
Well, the first thing we have
to ask is, what's the first

589
00:35:46,130 --> 00:35:48,290
thing it does?

590
00:35:48,290 --> 00:35:52,090
It sorts the list, right?

591
00:35:52,090 --> 00:35:57,330
So one thing that governs the
efficiency might be the amount

592
00:35:57,330 --> 00:36:03,020
of time it takes to sort
the list of items.

593
00:36:03,020 --> 00:36:06,580
Well, we know how
long that takes.

594
00:36:06,580 --> 00:36:08,960
Or we can speculate at least.

595
00:36:08,960 --> 00:36:12,210
And let's assume it does
something like merge sort.

596
00:36:12,210 --> 00:36:14,080
So what's that term
going to be?

597
00:36:14,080 --> 00:36:16,760

598
00:36:16,760 --> 00:36:18,095
Order what?

599
00:36:18,095 --> 00:36:25,110

600
00:36:25,110 --> 00:36:32,160
Len of items times what?

601
00:36:32,160 --> 00:36:33,410
Log n, right?

602
00:36:33,410 --> 00:36:41,210

603
00:36:41,210 --> 00:36:43,850
So maybe that's going
to tell us the

604
00:36:43,850 --> 00:36:47,410
complexity, but maybe not.

605
00:36:47,410 --> 00:36:51,630
The next thing we have to do is
look at the while loop and

606
00:36:51,630 --> 00:36:54,110
see how many times are we going
through the while loop.

607
00:36:54,110 --> 00:36:59,810

608
00:36:59,810 --> 00:37:01,060
What's the worst case?

609
00:37:01,060 --> 00:37:06,170

610
00:37:06,170 --> 00:37:07,050
Somebody?

611
00:37:07,050 --> 00:37:09,070
I know I didn't bring any candy
today, but you could

612
00:37:09,070 --> 00:37:10,985
answer the question anyway.

613
00:37:10,985 --> 00:37:12,440
Be a sport.

614
00:37:12,440 --> 00:37:13,480
Do it for free.

615
00:37:13,480 --> 00:37:15,782
Yeah?

616
00:37:15,782 --> 00:37:17,440
AUDIENCE: The length
of the items.

617
00:37:17,440 --> 00:37:26,879

618
00:37:26,879 --> 00:37:30,880
PROFESSOR: Well, we know
this one is bigger.

619
00:37:30,880 --> 00:37:34,530
So it looks like that's
the complexity, right?

620
00:37:34,530 --> 00:37:38,720

621
00:37:38,720 --> 00:37:43,910
So we can say, all right,
pretty good.

622
00:37:43,910 --> 00:37:47,420
Slightly worse than linear in
the length of the items, but

623
00:37:47,420 --> 00:37:50,570
not bad at all.

624
00:37:50,570 --> 00:37:54,390
And that's a big attraction
of greedy algorithms.

625
00:37:54,390 --> 00:38:00,930
They are typically order length
of items, or order

626
00:38:00,930 --> 00:38:04,430
length of items times the
log of the length.

627
00:38:04,430 --> 00:38:07,970
So greedy algorithms are usually
very close to linear.

628
00:38:07,970 --> 00:38:11,800
And that's why we really
like them.

629
00:38:11,800 --> 00:38:16,750
Why we don't like them is it may
be that the accumulation

630
00:38:16,750 --> 00:38:21,460
of a sequence of locally optimal
solutions does not

631
00:38:21,460 --> 00:38:23,260
yield a globally optimal
solution.

632
00:38:23,260 --> 00:38:26,420

633
00:38:26,420 --> 00:38:30,590
So now, let's ask the question,
suppose that's not

634
00:38:30,590 --> 00:38:32,380
good enough.

635
00:38:32,380 --> 00:38:36,330
I have a very demanding thief.

636
00:38:36,330 --> 00:38:40,450
Or maybe the thief works for
a very demanding person and

637
00:38:40,450 --> 00:38:45,610
needs to choose the absolute
optimal set.

638
00:38:45,610 --> 00:38:51,200
Let's think first about how we
formulate that carefully.

639
00:38:51,200 --> 00:38:55,180
And then, what the complexity
of solving it would be.

640
00:38:55,180 --> 00:39:00,180
And then, algorithms that
might be useful.

641
00:39:00,180 --> 00:39:04,060
Again, the important step here,
I think, is not the

642
00:39:04,060 --> 00:39:09,380
solution to the problem, but the
process used to formulate

643
00:39:09,380 --> 00:39:11,200
the problem.

644
00:39:11,200 --> 00:39:16,110
Often, it is the case that once
one has done a careful

645
00:39:16,110 --> 00:39:21,550
formulation of a problem, it
becomes obvious how to solve

646
00:39:21,550 --> 00:39:24,750
it, at least in a
brute force way.

647
00:39:24,750 --> 00:39:27,750
So now, let's look at a
formalization of the 0/1

648
00:39:27,750 --> 00:39:29,330
knapsack problem.

649
00:39:29,330 --> 00:39:31,720
And it's a kind of formalization
we'll use for a

650
00:39:31,720 --> 00:39:33,850
lot of problems.

651
00:39:33,850 --> 00:39:41,820
So step one, we'll represent
each item by a pair.

652
00:39:41,820 --> 00:39:51,530

653
00:39:51,530 --> 00:39:54,550
Because in fact, in deciding
whether or not to take an

654
00:39:54,550 --> 00:39:56,960
item, we don't care
what its name.

655
00:39:56,960 --> 00:40:00,260
We don't care if it's a clock,
or a radio, or whatever.

656
00:40:00,260 --> 00:40:03,330
What matters is what's its value
and what's its weight.

657
00:40:03,330 --> 00:40:07,300

658
00:40:07,300 --> 00:40:15,320
We'll write W as the maximum
weight that the thief can

659
00:40:15,320 --> 00:40:18,700
carry, or that can fit
in the knapsack.

660
00:40:18,700 --> 00:40:20,060
So far, so good.

661
00:40:20,060 --> 00:40:22,160
Nothing complicated there.

662
00:40:22,160 --> 00:40:26,230
Now comes the interesting
step.

663
00:40:26,230 --> 00:40:29,910
We're going to represent
the set of

664
00:40:29,910 --> 00:40:34,030
available items as a vector.

665
00:40:34,030 --> 00:40:57,750
We'll call it I. And then we'll
have another vector, V,

666
00:40:57,750 --> 00:41:02,670
which indicates whether or not
each item in I has been taken.

667
00:41:02,670 --> 00:41:05,290

668
00:41:05,290 --> 00:41:08,620
So V is a vector.

669
00:41:08,620 --> 00:41:23,050
And if V_i is equal to
1, that implies I_i--

670
00:41:23,050 --> 00:41:25,320
big I sub little i--

671
00:41:25,320 --> 00:41:29,560
has been taken, is
in the knapsack.

672
00:41:29,560 --> 00:41:33,360

673
00:41:33,360 --> 00:41:37,550
Conversely, if V_i is
0, it means I_i

674
00:41:37,550 --> 00:41:40,910
is not in the knapsack.

675
00:41:40,910 --> 00:41:52,080
So having formulated the
situation thusly, we can now

676
00:41:52,080 --> 00:41:56,370
go back to our notion of an
optimization problem as an

677
00:41:56,370 --> 00:42:01,580
objective function and a set
of constraints to carefully

678
00:42:01,580 --> 00:42:02,830
state the problem.

679
00:42:02,830 --> 00:42:05,440

680
00:42:05,440 --> 00:42:21,760
So for the objective function,
we want to maximize the sum of

681
00:42:21,760 --> 00:42:40,700
V_i times I_i dot value, where
i ranges over the length of

682
00:42:40,700 --> 00:42:42,270
the vectors.

683
00:42:42,270 --> 00:42:45,360
So that's the trick
of the 0/1.

684
00:42:45,360 --> 00:42:46,820
If I don't take it, it's 0.

685
00:42:46,820 --> 00:42:48,520
So it's 0 times the value.

686
00:42:48,520 --> 00:42:51,390
If I take it, it's 1
times the value.

687
00:42:51,390 --> 00:42:54,980
So this is going to give me the
sum of the values of the

688
00:42:54,980 --> 00:42:56,230
items I've taken.

689
00:42:56,230 --> 00:42:58,780

690
00:42:58,780 --> 00:43:01,175
And then, I have this subject
to the constraint.

691
00:43:01,175 --> 00:43:11,040

692
00:43:11,040 --> 00:43:13,970
And again, we'll
do a summation.

693
00:43:13,970 --> 00:43:16,945
And it will look very similar.

694
00:43:16,945 --> 00:43:31,330
V_i times I_i, but this time,
dot weight is less than or

695
00:43:31,330 --> 00:43:41,350
equal to W.

696
00:43:41,350 --> 00:43:46,830
Straightforward, but a
useful kind of skill.

697
00:43:46,830 --> 00:43:50,180
And people do spend a lot
of time on doing that.

698
00:43:50,180 --> 00:43:53,880
If you've ever used MATLAB, you
know it wants everything

699
00:43:53,880 --> 00:43:55,840
to be a vector.

700
00:43:55,840 --> 00:43:59,590
And that's often because a lot
of these problems can be

701
00:43:59,590 --> 00:44:04,570
nicely formulated in
this kind of way.

702
00:44:04,570 --> 00:44:10,620
All right, now let's return to
the question of complexity.

703
00:44:10,620 --> 00:44:14,360
What happens if we implement
this in the most

704
00:44:14,360 --> 00:44:15,610
straightforward way?

705
00:44:15,610 --> 00:44:18,220

706
00:44:18,220 --> 00:44:20,050
What would the most
straightforward

707
00:44:20,050 --> 00:44:23,050
implementation look like?

708
00:44:23,050 --> 00:44:46,660
Well, we could enumerate all
possibilities and then choose

709
00:44:46,660 --> 00:44:50,535
the best that meets
the constraint.

710
00:44:50,535 --> 00:44:55,280

711
00:44:55,280 --> 00:45:00,650
So this would be the obvious
brute force solution to the

712
00:45:00,650 --> 00:45:03,800
optimization problem.

713
00:45:03,800 --> 00:45:05,410
Look at all possible
solutions.

714
00:45:05,410 --> 00:45:09,100
Choose the best one.

715
00:45:09,100 --> 00:45:11,820
I think you can see immediately
that this is

716
00:45:11,820 --> 00:45:14,300
guaranteed to give you
the optimal solution.

717
00:45:14,300 --> 00:45:16,540
Actually, an optimal solution.

718
00:45:16,540 --> 00:45:20,080
Maybe there's more
than one best.

719
00:45:20,080 --> 00:45:23,750
But in that case, you can just
choose whichever one you like

720
00:45:23,750 --> 00:45:27,490
or whichever comes first,
for example.

721
00:45:27,490 --> 00:45:30,840
The question is, how long
will this take to run?

722
00:45:30,840 --> 00:45:34,260

723
00:45:34,260 --> 00:45:38,440
Well, we can think about that
by asking the question, how

724
00:45:38,440 --> 00:45:39,900
big will this set be?

725
00:45:39,900 --> 00:45:41,540
How many possibilities
are there?

726
00:45:41,540 --> 00:45:44,470

727
00:45:44,470 --> 00:45:48,140
Well, we can think about that
in a pretty straightforward

728
00:45:48,140 --> 00:45:57,300
way because if we look at our
formulation, we can ask

729
00:45:57,300 --> 00:46:02,640
ourselves, how many possible
vectors are there?

730
00:46:02,640 --> 00:46:07,960
How many vector V's could there
be which shows which

731
00:46:07,960 --> 00:46:10,110
items were taken and
which weren't?

732
00:46:10,110 --> 00:46:12,670
And what's the answer to that?

733
00:46:12,670 --> 00:46:23,340
Well, if we have n items,
how long will V be?

734
00:46:23,340 --> 00:46:24,920
Length n, right?

735
00:46:24,920 --> 00:46:27,430
0, 1 for each.

736
00:46:27,430 --> 00:46:32,150
If we have a vector of 0's and
1''s of length n, how many

737
00:46:32,150 --> 00:46:34,220
different values can that
vector take on?

738
00:46:34,220 --> 00:46:37,990

739
00:46:37,990 --> 00:46:39,790
We asked this question before.

740
00:46:39,790 --> 00:46:42,050
What's the answer?

741
00:46:42,050 --> 00:46:43,325
Somebody shout it out.

742
00:46:43,325 --> 00:46:45,960

743
00:46:45,960 --> 00:46:48,840
I've got a vector of length n.

744
00:46:48,840 --> 00:46:51,470

745
00:46:51,470 --> 00:46:55,050
Every value in the vector
is either a 0 or a 1.

746
00:46:55,050 --> 00:46:56,955
So maybe it looks something
like this.

747
00:46:56,955 --> 00:47:02,330

748
00:47:02,330 --> 00:47:05,440
How many possible combinations
of (0, 1)'s are there?

749
00:47:05,440 --> 00:47:06,292
AUDIENCE: 2 to the n?

750
00:47:06,292 --> 00:47:07,680
PROFESSOR: 2 to the n.

751
00:47:07,680 --> 00:47:11,960
Because essentially, this is
a binary number, exactly.

752
00:47:11,960 --> 00:47:16,490
And so if I had an n-bit binary
number, I can represent

753
00:47:16,490 --> 00:47:19,630
2 to the n different values.

754
00:47:19,630 --> 00:47:26,030
And so we see that we have 2 to
the n possible combinations

755
00:47:26,030 --> 00:47:28,370
to look at if we use a
brute force solution.

756
00:47:28,370 --> 00:47:31,650

757
00:47:31,650 --> 00:47:33,790
How bad is this?

758
00:47:33,790 --> 00:47:38,200
Well, if the number of items
is small, it's not so bad.

759
00:47:38,200 --> 00:47:42,630
And you'll see that, in fact, I
can run this on the example

760
00:47:42,630 --> 00:47:43,400
we've looked.

761
00:47:43,400 --> 00:47:47,500
2 to the 5 is not
a huge number.

762
00:47:47,500 --> 00:47:52,100
Suppose I have a different
number.

763
00:47:52,100 --> 00:47:56,440
Suppose I have 50 items
to choose from.

764
00:47:56,440 --> 00:47:58,940
Not a big problem.

765
00:47:58,940 --> 00:48:02,740
I heard yesterday that the
number of different airfares

766
00:48:02,740 --> 00:48:07,700
between two cities in the
US is order of 500 --

767
00:48:07,700 --> 00:48:09,080
500 different airfares between,

768
00:48:09,080 --> 00:48:11,620
say, Boston and Chicago.

769
00:48:11,620 --> 00:48:15,700
So looking at the best there
might be 2 to the 500, kind of

770
00:48:15,700 --> 00:48:17,260
a bigger number.

771
00:48:17,260 --> 00:48:18,570
Let's look at 2 to the 50.

772
00:48:18,570 --> 00:48:21,830

773
00:48:21,830 --> 00:48:23,810
Let's say there were
50 items to choose

774
00:48:23,810 --> 00:48:25,880
from in this question.

775
00:48:25,880 --> 00:48:30,610
And let's say for the sake
of argument, it takes a

776
00:48:30,610 --> 00:48:33,410
microsecond, one millionth
of a second,

777
00:48:33,410 --> 00:48:35,840
to generate a solution.

778
00:48:35,840 --> 00:48:39,830
How long will it take to solve
this problem in a brute force

779
00:48:39,830 --> 00:48:43,550
way for 50 items?

780
00:48:43,550 --> 00:48:47,950
Who thinks you can do it
in under four seconds?

781
00:48:47,950 --> 00:48:51,470
How about under four minutes?

782
00:48:51,470 --> 00:48:52,740
Wow, skeptics.

783
00:48:52,740 --> 00:48:53,600
Four hours?

784
00:48:53,600 --> 00:48:56,020
That's a lot of computation.

785
00:48:56,020 --> 00:48:57,790
Four hours, you're starting
to get some people.

786
00:48:57,790 --> 00:48:59,040
Four days?

787
00:48:59,040 --> 00:49:01,280

788
00:49:01,280 --> 00:49:02,050
All right.

789
00:49:02,050 --> 00:49:03,500
Well, how about four years?

790
00:49:03,500 --> 00:49:06,300

791
00:49:06,300 --> 00:49:09,150
Still longer, just under
four decades?

792
00:49:09,150 --> 00:49:12,000

793
00:49:12,000 --> 00:49:18,490
Looking at one choice every
microsecond, it takes you

794
00:49:18,490 --> 00:49:24,830
roughly 36 years to evaluate
all these possibilities.

795
00:49:24,830 --> 00:49:27,500
Certainly for people of my age,
that's not a practical

796
00:49:27,500 --> 00:49:31,800
solution to have to wait
36 years for an answer.

797
00:49:31,800 --> 00:49:35,110
So we have to find
something better.

798
00:49:35,110 --> 00:49:36,740
And we'll be talking
about that later.

799
00:49:36,740 --> 00:49:41,055