1
00:00:00,000 --> 00:00:00,040

2
00:00:00,040 --> 00:00:02,460
The following content is
provided under a Creative

3
00:00:02,460 --> 00:00:03,870
Commons license.

4
00:00:03,870 --> 00:00:06,910
Your support will help MIT
OpenCourseWare continue to

5
00:00:06,910 --> 00:00:10,560
offer high quality educational
resources for free.

6
00:00:10,560 --> 00:00:13,460
To make a donation or view
additional materials from

7
00:00:13,460 --> 00:00:19,290
hundreds of MIT courses, visit
MIT OpenCourseWare at

8
00:00:19,290 --> 00:00:21,006
ocw.mit.edu.

9
00:00:21,006 --> 00:00:21,500
PROFESSOR: All right.

10
00:00:21,500 --> 00:00:26,070
Today I want to spend a few more
minutes on plotting, and

11
00:00:26,070 --> 00:00:30,390
then return to a subject that
will occupy us for a couple of

12
00:00:30,390 --> 00:00:32,330
weeks, which is the use of

13
00:00:32,330 --> 00:00:34,665
randomness in solving problems.

14
00:00:34,665 --> 00:00:38,450

15
00:00:38,450 --> 00:00:39,700
Don't save.

16
00:00:39,700 --> 00:00:41,520

17
00:00:41,520 --> 00:00:44,360
All right, so let's
first look at one

18
00:00:44,360 --> 00:00:46,960
more example of plotting.

19
00:00:46,960 --> 00:00:48,210
It's simple.

20
00:00:48,210 --> 00:00:50,620
It's so simple you'll find
it's not in your handout.

21
00:00:50,620 --> 00:00:54,330

22
00:00:54,330 --> 00:00:56,190
So here it is to start with.

23
00:00:56,190 --> 00:01:02,180

24
00:01:02,180 --> 00:01:05,590
PROFESSOR: All I'm doing here is
I wrote a little program to

25
00:01:05,590 --> 00:01:09,800
show the effect of compound
interest, nothing very

26
00:01:09,800 --> 00:01:10,710
sophisticated.

27
00:01:10,710 --> 00:01:14,380
We start with some principal and
an interest rate, and then

28
00:01:14,380 --> 00:01:16,960
we just apply it over
and over again.

29
00:01:16,960 --> 00:01:22,890
And then we're going to plot to
show what the principal has

30
00:01:22,890 --> 00:01:25,260
become if we just keep
compounding the interest.

31
00:01:25,260 --> 00:01:30,830

32
00:01:30,830 --> 00:01:33,940
So it is kind of what
you'd expect.

33
00:01:33,940 --> 00:01:35,830
Compound interest is
a nice formula.

34
00:01:35,830 --> 00:01:39,700
You can actually get rich
applying it, and we see this

35
00:01:39,700 --> 00:01:40,950
nice little graph.

36
00:01:40,950 --> 00:01:44,260

37
00:01:44,260 --> 00:01:48,040
On the other hand, we can't
really tell what it is.

38
00:01:48,040 --> 00:01:52,790
And this is the sort of thing
that I see all too often,

39
00:01:52,790 --> 00:01:54,800
including my graduate
students produce it.

40
00:01:54,800 --> 00:01:57,440
They come to my office, they
show me a graph, and they

41
00:01:57,440 --> 00:01:58,570
start explaining it.

42
00:01:58,570 --> 00:02:03,150
And I usually refuse to look at
it if it looks like this.

43
00:02:03,150 --> 00:02:07,245
There is no point in ever, and I
mean ever, producing a graph

44
00:02:07,245 --> 00:02:12,060
that does not have a title
and labeled axes.

45
00:02:12,060 --> 00:02:15,280
And in particular, you have
to label the axes to

46
00:02:15,280 --> 00:02:17,500
say what they mean.

47
00:02:17,500 --> 00:02:22,300
Fortunately, it's easy
enough to do.

48
00:02:22,300 --> 00:02:25,425
And here, I've just done that.

49
00:02:25,425 --> 00:02:29,930

50
00:02:29,930 --> 00:02:35,430
So I'm going to run the same
code to compute the interest,

51
00:02:35,430 --> 00:02:39,130
but I'm going to put a
title on the graph.

52
00:02:39,130 --> 00:02:40,630
You've seen this before,
I just want to

53
00:02:40,630 --> 00:02:42,860
remind you how it works.

54
00:02:42,860 --> 00:02:47,200
PyLab.title And then I'm
going to label the

55
00:02:47,200 --> 00:02:48,540
x-axis and the y-axis.

56
00:02:48,540 --> 00:02:55,010

57
00:02:55,010 --> 00:02:57,750
And that gives me a much
more useful graph.

58
00:02:57,750 --> 00:03:02,130

59
00:03:02,130 --> 00:03:04,860
Nothing magical here, it's
just a reminder that you

60
00:03:04,860 --> 00:03:07,780
really need to do
these things.

61
00:03:07,780 --> 00:03:11,150
You'll notice here I've not only
told you that this is the

62
00:03:11,150 --> 00:03:14,410
years of compounding and that
this is the principal but I've

63
00:03:14,410 --> 00:03:16,220
measured it in dollars.

64
00:03:16,220 --> 00:03:19,090
Maybe I should have been even
more explicit and said, well,

65
00:03:19,090 --> 00:03:21,860
US dollars, whatever.

66
00:03:21,860 --> 00:03:26,750
One of the things I did want
to point out is you saw the

67
00:03:26,750 --> 00:03:29,620
two of these various icons that
will let you do things

68
00:03:29,620 --> 00:03:32,980
like zoom in on a graph
and save a graph.

69
00:03:32,980 --> 00:03:36,490
Here's this icon that I think
Professor Grimson mentioned,

70
00:03:36,490 --> 00:03:37,960
in fact, I know he did.

71
00:03:37,960 --> 00:03:42,780
It's a floppy disk, just in case
you've never seen one, I

72
00:03:42,780 --> 00:03:44,840
brought a floppy disk
to show you.

73
00:03:44,840 --> 00:03:48,950
This is one of the older
floppy disks.

74
00:03:48,950 --> 00:03:54,160
These were invented
in 1971 by IBM.

75
00:03:54,160 --> 00:03:58,590
They were originally 8 inches in
diameter and held all of 80

76
00:03:58,590 --> 00:04:02,100
kilobytes of data.

77
00:04:02,100 --> 00:04:04,900
And as you can see, unlike
later floppy disks, they

78
00:04:04,900 --> 00:04:07,250
actually flopped.

79
00:04:07,250 --> 00:04:11,610
Eventually, Apple and others
pioneered a non-floppy floppy

80
00:04:11,610 --> 00:04:17,600
disk, that was in the '80s.

81
00:04:17,600 --> 00:04:21,700
The interesting thing today is I
typically carry around a USB

82
00:04:21,700 --> 00:04:27,030
stick with me about that big
that holds roughly 400,000

83
00:04:27,030 --> 00:04:29,720
times more data than
this floppy.

84
00:04:29,720 --> 00:04:33,980
And so it's just quite
incredible how things have

85
00:04:33,980 --> 00:04:35,230
gone along.

86
00:04:35,230 --> 00:04:35,980
All right.

87
00:04:35,980 --> 00:04:40,390
I now want to return to what
will be the main theme for, as

88
00:04:40,390 --> 00:04:43,630
I said, a couple of weeks
which is randomness.

89
00:04:43,630 --> 00:04:46,290
And in order to talk about
randomness we have to talk

90
00:04:46,290 --> 00:04:49,090
about probability.

91
00:04:49,090 --> 00:04:53,610
And I know that Professor
Grimson started down that path

92
00:04:53,610 --> 00:04:57,040
just before spring break, but
if you're anything like me

93
00:04:57,040 --> 00:04:59,970
your mind kind of deteriorated
a little bit over spring

94
00:04:59,970 --> 00:05:03,200
break, and your head isn't
quite into things.

95
00:05:03,200 --> 00:05:08,050
And so, I'm just going to back
up a tiny bit and start over

96
00:05:08,050 --> 00:05:11,690
to get our heads into it, and
then fairly quickly move on to

97
00:05:11,690 --> 00:05:14,010
new things.

98
00:05:14,010 --> 00:05:19,070
So let's start by asking
a simple question.

99
00:05:19,070 --> 00:05:21,890
You can tell my head isn't
quite yet back to things

100
00:05:21,890 --> 00:05:28,520
because I forgot that I needed
to begin by gathering chalk.

101
00:05:28,520 --> 00:05:29,770
I've now got it.

102
00:05:29,770 --> 00:05:33,760

103
00:05:33,760 --> 00:05:36,015
And we'll come over here and
take a look at some examples.

104
00:05:36,015 --> 00:05:43,236

105
00:05:43,236 --> 00:05:44,110
All right.

106
00:05:44,110 --> 00:05:49,710
So the first question I want
to ask is, suppose I take a

107
00:05:49,710 --> 00:05:54,630
6-sided die, a fair one, and I
roll it 10 times, what's the

108
00:05:54,630 --> 00:06:02,450
probability of not getting a
single 1, out of that die?

109
00:06:02,450 --> 00:06:07,000
Well, how do we go about
answering this?

110
00:06:07,000 --> 00:06:12,390
Well, there is a wrong way to
do it, which is sort of the

111
00:06:12,390 --> 00:06:16,970
obvious way, and many people
will start down this path.

112
00:06:16,970 --> 00:06:18,480
They'll say, well the
probability of

113
00:06:18,480 --> 00:06:20,280
rolling a 1 on the--

114
00:06:20,280 --> 00:06:23,950
not rolling a 1 on the first
try is 1 over 6.

115
00:06:23,950 --> 00:06:29,130

116
00:06:29,130 --> 00:06:31,030
Right?

117
00:06:31,030 --> 00:06:32,090
That's true?

118
00:06:32,090 --> 00:06:32,950
That's not true.

119
00:06:32,950 --> 00:06:36,230
What's the probability of not
rolling a 1 the first time?

120
00:06:36,230 --> 00:06:37,510
5 over 6.

121
00:06:37,510 --> 00:06:41,812

122
00:06:41,812 --> 00:06:43,810
All right.

123
00:06:43,810 --> 00:06:48,280
What's the probability of not
rolling a 1 on the second try?

124
00:06:48,280 --> 00:06:50,430
5 over 6.

125
00:06:50,430 --> 00:06:54,100
Well, the wrong thing to do, of
course, would be to start

126
00:06:54,100 --> 00:06:56,830
adding them up.

127
00:06:56,830 --> 00:07:00,950
We say, well, OK, we'll
just add these up.

128
00:07:00,950 --> 00:07:07,780
Well, one way we can tell that's
wrong is if we add up

129
00:07:07,780 --> 00:07:11,040
10 of these, we get
more than 1.

130
00:07:11,040 --> 00:07:15,910
Probabilities can never be
more than 1 as we'll see.

131
00:07:15,910 --> 00:07:18,050
So let's now try and think
of the right way to

132
00:07:18,050 --> 00:07:19,300
look at this problem.

133
00:07:19,300 --> 00:07:21,500

134
00:07:21,500 --> 00:07:24,160
So you can think about it.

135
00:07:24,160 --> 00:07:27,230
If we roll these--

136
00:07:27,230 --> 00:07:32,840
a die 10 times, each time
I'll get a number.

137
00:07:32,840 --> 00:07:38,230
So I might get a 3, and then
a 4, and then a 2.

138
00:07:38,230 --> 00:07:42,470
How many possible 10-digit
numbers are there?

139
00:07:42,470 --> 00:07:44,870
On a 6-sided die, if
I roll it 10 times?

140
00:07:44,870 --> 00:07:48,860

141
00:07:48,860 --> 00:07:51,840
How many?

142
00:07:51,840 --> 00:07:53,736
AUDIENCE: 6 to the 10th?

143
00:07:53,736 --> 00:07:55,640
PROFESSOR: 6 to the 10th.

144
00:07:55,640 --> 00:08:02,870
Exactly Just when we look at
binary numbers, if I take a

145
00:08:02,870 --> 00:08:06,170
10-digit binary number, and ask
how many different numbers

146
00:08:06,170 --> 00:08:08,420
can I represent in 10 binary
digits, it's going

147
00:08:08,420 --> 00:08:10,930
to be 2 to the 10th.

148
00:08:10,930 --> 00:08:13,460
Here we're base 6.

149
00:08:13,460 --> 00:08:16,470
So it's going to be
6 to the 10th.

150
00:08:16,470 --> 00:08:18,660
Pretty big number.

151
00:08:18,660 --> 00:08:23,840
Now I can say, how many
of those numbers

152
00:08:23,840 --> 00:08:25,090
don't contain a 1?

153
00:08:25,090 --> 00:08:30,300

154
00:08:30,300 --> 00:08:30,550
All right.

155
00:08:30,550 --> 00:08:33,400
So that's really the question
I'm now asking.

156
00:08:33,400 --> 00:08:36,830
How many of these don't
contain a 1?

157
00:08:36,830 --> 00:08:43,600
So as we said, if I look at the
first roll the odds of not

158
00:08:43,600 --> 00:08:50,600
getting a one the first time
is 5 over 6 Now what's the

159
00:08:50,600 --> 00:08:56,060
odds of not getting 1 the first
or the second time?

160
00:08:56,060 --> 00:09:01,575
It's 5 over 6 times 5 over 6.

161
00:09:01,575 --> 00:09:07,080

162
00:09:07,080 --> 00:09:08,750
That makes sense?

163
00:09:08,750 --> 00:09:13,660
Because these are independent
events.

164
00:09:13,660 --> 00:09:16,490
And that's a key notion here.

165
00:09:16,490 --> 00:09:20,490
I'm assuming that whether I get
a 1 on the second roll is

166
00:09:20,490 --> 00:09:22,885
independent of whether I got
a 1 on the first roll.

167
00:09:22,885 --> 00:09:25,920

168
00:09:25,920 --> 00:09:30,200
It should be true, assuming
my dice--

169
00:09:30,200 --> 00:09:32,560
die is fair.

170
00:09:32,560 --> 00:09:40,920
Similarly, I can do this for
the third roll et cetera.

171
00:09:40,920 --> 00:09:46,260
So the probability of not
getting a 1 in 10 rolls is

172
00:09:46,260 --> 00:09:51,595
going to be (5 over
6) to the 10th.

173
00:09:51,595 --> 00:09:58,770

174
00:09:58,770 --> 00:10:01,170
That makes sense?

175
00:10:01,170 --> 00:10:03,980
If not, speak up, because things
are going to get more

176
00:10:03,980 --> 00:10:05,230
complicated quickly.

177
00:10:05,230 --> 00:10:08,250

178
00:10:08,250 --> 00:10:09,680
All right.

179
00:10:09,680 --> 00:10:12,115
So that's pretty simple.

180
00:10:12,115 --> 00:10:16,570

181
00:10:16,570 --> 00:10:17,100
You--

182
00:10:17,100 --> 00:10:18,690
you all-- are you all
with me on that?

183
00:10:18,690 --> 00:10:21,810

184
00:10:21,810 --> 00:10:26,360
Now, suppose I ask you
the inverse question.

185
00:10:26,360 --> 00:10:30,240
What is the probability of
getting at least one 1 if I

186
00:10:30,240 --> 00:10:31,490
roll the die 10 times?

187
00:10:31,490 --> 00:10:35,320

188
00:10:35,320 --> 00:10:39,130
So here I've given you how to
compute the probability of not

189
00:10:39,130 --> 00:10:40,810
getting any 1's.

190
00:10:40,810 --> 00:10:46,290
Suppose I asked you the
probability of at least one 1?

191
00:10:46,290 --> 00:10:46,665
Yeah?

192
00:10:46,665 --> 00:10:48,040
AUDIENCE: [INAUDIBLE]

193
00:10:48,040 --> 00:10:50,040
1 minus not having a 1?

194
00:10:50,040 --> 00:10:51,040
PROFESSOR: Exactly.

195
00:10:51,040 --> 00:10:52,540
Thank you.

196
00:10:52,540 --> 00:11:02,430
So that would be 1 minus because
we know that the

197
00:11:02,430 --> 00:11:06,900
probability, the sum of all the
possible things that we

198
00:11:06,900 --> 00:11:08,680
can do when we do a probability

199
00:11:08,680 --> 00:11:10,620
always has to be 1.

200
00:11:10,620 --> 00:11:16,230

201
00:11:16,230 --> 00:11:19,434
It was a good effort.

202
00:11:19,434 --> 00:11:20,840
That's it.

203
00:11:20,840 --> 00:11:21,860
If you take--

204
00:11:21,860 --> 00:11:24,500
if you want to get something
where everything is covered,

205
00:11:24,500 --> 00:11:28,700
the probabilities always
have to sum to 1.

206
00:11:28,700 --> 00:11:31,640
And so now, there are only
two possibilities here.

207
00:11:31,640 --> 00:11:34,760
One possibility is I
don't get any 1's.

208
00:11:34,760 --> 00:11:39,350
One possibility is I
get at least one 1.

209
00:11:39,350 --> 00:11:44,550
So if I take all of the
possibilities, and I subtract

210
00:11:44,550 --> 00:11:48,020
the possibilities of not getting
any 1's, the result

211
00:11:48,020 --> 00:11:52,800
must be the probability of
getting at least one 1.

212
00:11:52,800 --> 00:11:58,710
This is a very common trick in
computing probabilities.

213
00:11:58,710 --> 00:12:02,160
Very often when I ask or
somebody says, what's the

214
00:12:02,160 --> 00:12:04,550
probability of x?

215
00:12:04,550 --> 00:12:07,470
The simplest way to compute
it, is to compute the

216
00:12:07,470 --> 00:12:11,210
probability of not x and
subtract it from 1.

217
00:12:11,210 --> 00:12:17,700

218
00:12:17,700 --> 00:12:17,980
OK.

219
00:12:17,980 --> 00:12:22,350
Again, heading down a wrong
track for this, one might have

220
00:12:22,350 --> 00:12:26,010
said, well all right, the
probability of getting a 1 on

221
00:12:26,010 --> 00:12:32,020
the first roll is 1 over 6.

222
00:12:32,020 --> 00:12:33,960
The probability of getting
a 1 on the second

223
00:12:33,960 --> 00:12:35,235
roll is 1 over 6.

224
00:12:35,235 --> 00:12:38,850
The probability of getting
a third roll is 1 over 6.

225
00:12:38,850 --> 00:12:40,640
I'll just add them up, and
that will give me the

226
00:12:40,640 --> 00:12:44,260
probability of getting
at least one one.

227
00:12:44,260 --> 00:12:45,080
How do I--

228
00:12:45,080 --> 00:12:47,320
how can I be sure
that's wrong?

229
00:12:47,320 --> 00:12:50,840
Well when I'm done, I would
claim the probability is

230
00:12:50,840 --> 00:12:53,510
something like that.

231
00:12:53,510 --> 00:12:55,470
And we know that
can't be true.

232
00:12:55,470 --> 00:12:58,290
Because a probability always
has to be less

233
00:12:58,290 --> 00:13:00,890
than or equal to 1.

234
00:13:00,890 --> 00:13:03,820
So this is a good trick to keep
in mind, whenever you're

235
00:13:03,820 --> 00:13:07,840
given a probability problem, try
and figure out whether you

236
00:13:07,840 --> 00:13:10,890
have a good way to compute it
directly, or whether it's

237
00:13:10,890 --> 00:13:17,680
simpler to compute the not of
the probability, and then

238
00:13:17,680 --> 00:13:20,710
subtract it from 1.

239
00:13:20,710 --> 00:13:25,840
Probability is really
a fun field.

240
00:13:25,840 --> 00:13:28,910
It's interesting, it's history,
it's intimately

241
00:13:28,910 --> 00:13:31,680
connected with the history
of gambling.

242
00:13:31,680 --> 00:13:36,710
And, in fact, almost all of
early probability theory owes

243
00:13:36,710 --> 00:13:40,090
its existence to gamblers.

244
00:13:40,090 --> 00:13:44,550
People like Cardano, Pascal,
Fermat, Bernoulli, de Moivre,

245
00:13:44,550 --> 00:13:48,990
Laplace, all famous names you've
heard, were motivated

246
00:13:48,990 --> 00:13:51,760
by desire to understand
games of chance.

247
00:13:51,760 --> 00:13:55,260

248
00:13:55,260 --> 00:13:57,980
Mostly, it started with dice.

249
00:13:57,980 --> 00:14:00,100
I've been talking about dice.

250
00:14:00,100 --> 00:14:03,960
And in fact, dice are probably
the human race's oldest

251
00:14:03,960 --> 00:14:05,210
gambling implement.

252
00:14:05,210 --> 00:14:07,530

253
00:14:07,530 --> 00:14:10,600
They date at least,
archaeologically, to about 600

254
00:14:10,600 --> 00:14:15,960
BC, where a pair of dice was
found in Egyptian tombs,

255
00:14:15,960 --> 00:14:17,660
actually longer than that.

256
00:14:17,660 --> 00:14:21,110
Two millennia before the birth
of Christ, people found dice

257
00:14:21,110 --> 00:14:22,360
in Egyptian tombs.

258
00:14:22,360 --> 00:14:24,580

259
00:14:24,580 --> 00:14:27,350
Typically, they were made
from animal bones, but

260
00:14:27,350 --> 00:14:28,960
that doesn't matter.

261
00:14:28,960 --> 00:14:32,230
Pascal's interest in it, and
Pascal is really considered

262
00:14:32,230 --> 00:14:35,840
the founder of probability
theory, came when a friend

263
00:14:35,840 --> 00:14:38,730
asked him to solve the following
problem which I want

264
00:14:38,730 --> 00:14:42,300
to work out with you.

265
00:14:42,300 --> 00:14:47,590
Is it profitable to bet that
given 24 rolls of a pair of

266
00:14:47,590 --> 00:14:51,535
fair dice, you would
roll a double 6?

267
00:14:51,535 --> 00:14:54,220

268
00:14:54,220 --> 00:14:57,070
He actually had a friend who
was in the business of

269
00:14:57,070 --> 00:14:59,180
gambling, making these bets.

270
00:14:59,180 --> 00:15:07,290
So he said, you've got a pair of
dice, you roll it 24 times

271
00:15:07,290 --> 00:15:12,830
and ask the question, what is
the probability of getting

272
00:15:12,830 --> 00:15:16,220
what we call today "box cars",
in those days they

273
00:15:16,220 --> 00:15:19,540
just called two 6's.

274
00:15:19,540 --> 00:15:23,060
This was considered a really
hard problem in

275
00:15:23,060 --> 00:15:25,430
the mid-17th century.

276
00:15:25,430 --> 00:15:31,080
And in fact, Pascal and Fermat,
two pretty smart guys

277
00:15:31,080 --> 00:15:33,190
as it happens, debated this.

278
00:15:33,190 --> 00:15:35,540
They exchanged letters with each
other trying to figure

279
00:15:35,540 --> 00:15:37,490
out how to solve this problem.

280
00:15:37,490 --> 00:15:40,920
It shows how math has advanced
because, in fact, today, it's

281
00:15:40,920 --> 00:15:42,830
quite an easy problem.

282
00:15:42,830 --> 00:15:45,680
So let's work it through
and think how would

283
00:15:45,680 --> 00:15:50,070
we answer this question.

284
00:15:50,070 --> 00:16:00,560
So what's the probability of
rolling, of not rolling, a

285
00:16:00,560 --> 00:16:03,475
double 6 on the first try?

286
00:16:03,475 --> 00:16:06,910

287
00:16:06,910 --> 00:16:10,650
Well, the probability of
not rolling a 6 on one

288
00:16:10,650 --> 00:16:12,000
die is a sixth --

289
00:16:12,000 --> 00:16:13,900
1 over 6.

290
00:16:13,900 --> 00:16:16,900
The probability of not rolling
a one with the next die is

291
00:16:16,900 --> 00:16:20,170
also 1 over 6.

292
00:16:20,170 --> 00:16:23,340
So the probability of not
getting a die in the first

293
00:16:23,340 --> 00:16:26,760
roll, first double 6's is--

294
00:16:26,760 --> 00:16:29,750

295
00:16:29,750 --> 00:16:34,170
the probability of getting
a double 6 is 1/36.

296
00:16:34,170 --> 00:16:38,395
So the probability of not
getting a double 6 is 35/36.

297
00:16:38,395 --> 00:16:41,800

298
00:16:41,800 --> 00:16:44,350
Right?

299
00:16:44,350 --> 00:16:48,880
So now we know that the
probability of not

300
00:16:48,880 --> 00:16:50,170
getting it is that.

301
00:16:50,170 --> 00:16:52,690

302
00:16:52,690 --> 00:16:57,050
What's the probability of not
getting it 24 times in a row?

303
00:16:57,050 --> 00:17:00,310

304
00:17:00,310 --> 00:17:01,560
It's that.

305
00:17:01,560 --> 00:17:05,960

306
00:17:05,960 --> 00:17:12,000
Which is approximately
equal to 0.51.

307
00:17:12,000 --> 00:17:15,550
So you can see why the answer
was not obvious just by

308
00:17:15,550 --> 00:17:17,670
experience.

309
00:17:17,670 --> 00:17:24,960
But there is a slight edge in
betting that you will not get

310
00:17:24,960 --> 00:17:28,369
a double 6 in 24 times.

311
00:17:28,369 --> 00:17:30,580
Again, assuming you
have fair dice.

312
00:17:30,580 --> 00:17:34,220
As old as dice is, people have
built cheater's dice.

313
00:17:34,220 --> 00:17:37,450
The excavation of Pompeii, for
example, they discovered a

314
00:17:37,450 --> 00:17:41,050
pair of loaded dice, dice with
a little weight in it so one

315
00:17:41,050 --> 00:17:45,100
number would come up more
often than it should.

316
00:17:45,100 --> 00:17:47,210
And in fact, if you look at the
internet today, you will

317
00:17:47,210 --> 00:17:51,880
find many sites where you can,
let's see, the one I found

318
00:17:51,880 --> 00:17:55,290
this morning says quote, "Are
you on unusually unlucky when

319
00:17:55,290 --> 00:17:57,780
it comes to rolling dice?

320
00:17:57,780 --> 00:18:01,640
Investing in a pair of dice
that's more reliable might be

321
00:18:01,640 --> 00:18:05,770
just what you need." And then
it says, "Of course for

322
00:18:05,770 --> 00:18:10,530
amusement only." Yeah,
we believe that.

323
00:18:10,530 --> 00:18:12,420
All right.

324
00:18:12,420 --> 00:18:17,050
As much as I trust probability
theory, I don't trust my

325
00:18:17,050 --> 00:18:18,940
ability to use it.

326
00:18:18,940 --> 00:18:28,270
And so what I did is wrote a
little simulation to see if

327
00:18:28,270 --> 00:18:32,240
Pascal was right when
he did this.

328
00:18:32,240 --> 00:18:38,130
So I've got the first-- just
this little test roll, which

329
00:18:38,130 --> 00:18:42,205
rolls a dice number of times,
gets the result.

330
00:18:42,205 --> 00:18:46,360

331
00:18:46,360 --> 00:18:50,310
Now, then I decided
to check Pascal.

332
00:18:50,310 --> 00:18:55,300
So I was going to run 100,000
trials, and keep track of the

333
00:18:55,300 --> 00:18:57,940
number of times it worked.

334
00:18:57,940 --> 00:19:00,880
So what you'll see I'm doing
here is for i in the range

335
00:19:00,880 --> 00:19:04,400
number of trials, and this is
the way we'll do a lot of

336
00:19:04,400 --> 00:19:06,760
these simulations.

337
00:19:06,760 --> 00:19:12,110
And in fact, as we deal with
probability, we'll be dealing

338
00:19:12,110 --> 00:19:19,580
a lot with the notion of
simulation, as you are doing

339
00:19:19,580 --> 00:19:22,950
in your current problem set.

340
00:19:22,950 --> 00:19:28,770
So for i in range number of
trials, for j in range 24,

341
00:19:28,770 --> 00:19:33,500
because that was Pascal's
friend's game, I'll roll the

342
00:19:33,500 --> 00:19:36,230
first die, I'll roll
the second die.

343
00:19:36,230 --> 00:19:39,710
If they're both 6's I'll
say, yes equals 1.

344
00:19:39,710 --> 00:19:47,190
And I'll break and then I'll
compute the probability of

345
00:19:47,190 --> 00:19:48,440
winning or losing.

346
00:19:48,440 --> 00:19:50,800

347
00:19:50,800 --> 00:19:52,050
OK?

348
00:19:52,050 --> 00:19:54,010

349
00:19:54,010 --> 00:19:57,258
So let's let it rip.

350
00:19:57,258 --> 00:19:58,970
So now let's let it rip.

351
00:19:58,970 --> 00:20:11,150

352
00:20:11,150 --> 00:20:12,860
There it is.

353
00:20:12,860 --> 00:20:15,670
And we can see that it actually
comes out pretty

354
00:20:15,670 --> 00:20:20,980
close to what Pascal
predicted.

355
00:20:20,980 --> 00:20:24,560
Should we be surprised that it
didn't come out to exactly?

356
00:20:24,560 --> 00:20:27,030
Well let's see, is it exactly?

357
00:20:27,030 --> 00:20:30,330
What is 35/36 to the 24th?

358
00:20:30,330 --> 00:20:46,120

359
00:20:46,120 --> 00:20:48,482
So that's the--

360
00:20:48,482 --> 00:20:52,630
well, to 17 digits of precision,
the exact answer.

361
00:20:52,630 --> 00:20:55,950
And you can see we came up with
something close to that.

362
00:20:55,950 --> 00:20:59,470
Not exactly that, and we
wouldn't expect to.

363
00:20:59,470 --> 00:21:01,990
Now I only did 100,000 trials.

364
00:21:01,990 --> 00:21:05,440
If I did a million trials,
I'd probably come up with

365
00:21:05,440 --> 00:21:09,410
something even closer, but if I
did 2 trials, who knows what

366
00:21:09,410 --> 00:21:11,244
I get-- come up with it, right?

367
00:21:11,244 --> 00:21:13,464
Could be--

368
00:21:13,464 --> 00:21:19,010
I could get 1, I could get lucky
both times, or unlucky.

369
00:21:19,010 --> 00:21:22,200
Later on, we'll talk more about
the question, how do we

370
00:21:22,200 --> 00:21:25,460
know how many trials to run?

371
00:21:25,460 --> 00:21:31,030
Now, the interesting thing is
I'm sure it took me less time

372
00:21:31,030 --> 00:21:33,040
to write this program
than it took Pascal

373
00:21:33,040 --> 00:21:34,820
to solve the problem.

374
00:21:34,820 --> 00:21:37,410
Now the truth is, I had several
hundred years of other

375
00:21:37,410 --> 00:21:39,690
people's work to build on.

376
00:21:39,690 --> 00:21:44,270
But in general, I think one of
the questions you'll find is,

377
00:21:44,270 --> 00:21:48,365
is it easier sometimes to write
a simulation, than it is

378
00:21:48,365 --> 00:21:53,230
to do the probabilities?

379
00:21:53,230 --> 00:21:57,550
What I often do in
practice is both.

380
00:21:57,550 --> 00:22:00,920
I'll scratch my head and figure
out how to figure out

381
00:22:00,920 --> 00:22:04,060
the answer analytically, and
then if it's easy, I'll write

382
00:22:04,060 --> 00:22:08,850
some code to simulate the
problem, and expect to get

383
00:22:08,850 --> 00:22:12,310
roughly the same answer, giving
me confidence I've done

384
00:22:12,310 --> 00:22:14,000
it correctly.

385
00:22:14,000 --> 00:22:16,400
On the other hand, if I've done
the simulation and it had

386
00:22:16,400 --> 00:22:20,980
come up with something totally
bogus, or totally different,

387
00:22:20,980 --> 00:22:23,150
then I would have had to work
hard to figure out which was

388
00:22:23,150 --> 00:22:27,400
right, the code or the math.

389
00:22:27,400 --> 00:22:29,770
Same sort of thing you saw when
you looked at the random

390
00:22:29,770 --> 00:22:33,340
walk, and the first time it was
done an answer showed up

391
00:22:33,340 --> 00:22:36,340
that was just wrong.

392
00:22:36,340 --> 00:22:40,730
But, you need to have some
intuition about a problem, so

393
00:22:40,730 --> 00:22:42,940
that you can look at
it and say, yeah,

394
00:22:42,940 --> 00:22:44,680
that's in the ballpark.

395
00:22:44,680 --> 00:22:48,790
And if it's not, it's
time to worry.

396
00:22:48,790 --> 00:22:51,770
This kind of simulation that
I've just done for the dice

397
00:22:51,770 --> 00:22:54,886
game is what's called a "Monte
Carlo simulation".

398
00:22:54,886 --> 00:23:03,660

399
00:23:03,660 --> 00:23:11,850
It is the most popular kind of
simulation named after a

400
00:23:11,850 --> 00:23:21,940
Casino on the Riviera, in the
small principality of Monaco.

401
00:23:21,940 --> 00:23:24,420
This was back in the time when
it was hard to find a place

402
00:23:24,420 --> 00:23:26,840
you could gamble, and this
happened to be one of the

403
00:23:26,840 --> 00:23:30,180
places you could.

404
00:23:30,180 --> 00:23:35,865
The term was coined in 1949 by
Stanislaw Ulam and Nicholas

405
00:23:35,865 --> 00:23:42,110
Metropolis, two very well-known
mathematicians.

406
00:23:42,110 --> 00:23:46,020
Ulam, who later became famous
for designing the hydrogen

407
00:23:46,020 --> 00:23:53,300
bomb with Teller, invented the
method in 1946, and I'm going

408
00:23:53,300 --> 00:23:58,130
to quote from his description
of how he invented it.

409
00:23:58,130 --> 00:24:00,710
"The first thoughts and attempts
I made to practice

410
00:24:00,710 --> 00:24:04,180
the Monte Carlo method, were
suggested by a question which

411
00:24:04,180 --> 00:24:08,110
occurred to me in 1946, as I
was convalescing from an

412
00:24:08,110 --> 00:24:11,010
illness and playing
solitaires.

413
00:24:11,010 --> 00:24:13,740
The question was, what are the
chances that a canfield

414
00:24:13,740 --> 00:24:16,990
solitaire laid out with
52 cards will come out

415
00:24:16,990 --> 00:24:18,990
successfully?

416
00:24:18,990 --> 00:24:21,880
After spending a lot of time
trying to estimate them by

417
00:24:21,880 --> 00:24:25,310
pure combinatorial calculations,
I wondered

418
00:24:25,310 --> 00:24:28,800
whether a more practical method
than quote 'abstract

419
00:24:28,800 --> 00:24:33,210
thinking' end quote, might not
be to lay it out, say, 100

420
00:24:33,210 --> 00:24:36,520
times, and simply observe
and count the number

421
00:24:36,520 --> 00:24:39,500
of successful plays.

422
00:24:39,500 --> 00:24:42,790
This was already possible to
envision with the beginning of

423
00:24:42,790 --> 00:24:45,920
the new era of fast computers.

424
00:24:45,920 --> 00:24:48,780
And I immediately thought of
problems, as you would, I'm

425
00:24:48,780 --> 00:24:52,010
sure, immediately thought of
problems of neutron diffusion

426
00:24:52,010 --> 00:24:55,260
and other questions of
mathematical physics.

427
00:24:55,260 --> 00:24:59,040
And more generally, how to
change processes described by

428
00:24:59,040 --> 00:25:02,680
certain differential equations
into an equivalent form

429
00:25:02,680 --> 00:25:07,610
interpretable as a succession
of random operations.

430
00:25:07,610 --> 00:25:11,480
Later, I described the idea to
John von Neumann, and we began

431
00:25:11,480 --> 00:25:14,460
to plan actual calculations."

432
00:25:14,460 --> 00:25:17,880
So as early as 1946, people
were thinking about the

433
00:25:17,880 --> 00:25:22,820
question of moving away from
solving systems of equations,

434
00:25:22,820 --> 00:25:28,230
to using randomized techniques
to simulate things and try to

435
00:25:28,230 --> 00:25:32,600
find out what the actual
answer was that way.

436
00:25:32,600 --> 00:25:35,810
Now of course "fast"
is a relative term.

437
00:25:35,810 --> 00:25:39,820
Ulam was probably referring to
the ENIAC computer, which

438
00:25:39,820 --> 00:25:44,180
could perform about 10 to the
3 additions a second.

439
00:25:44,180 --> 00:25:47,110
Not very many, 1,000 operations
a second, and

440
00:25:47,110 --> 00:25:50,760
weighed approximately 25 tons.

441
00:25:50,760 --> 00:25:53,620
Now today's computers, by
comparison, perform 10 to the

442
00:25:53,620 --> 00:25:58,490
9th additions and weigh about
10 to the minus 3 tons.

443
00:25:58,490 --> 00:25:59,090
All right.

444
00:25:59,090 --> 00:26:02,390
This technique was used during
the Manhattan Project to

445
00:26:02,390 --> 00:26:04,220
predict what would
happen doing--

446
00:26:04,220 --> 00:26:07,050
during nuclear fission
and worked.

447
00:26:07,050 --> 00:26:09,550

448
00:26:09,550 --> 00:26:15,950
Monte Carlo simulations are an
example of what's called

449
00:26:15,950 --> 00:26:17,200
"inferential statistics".

450
00:26:17,200 --> 00:26:28,400

451
00:26:28,400 --> 00:26:30,930
In brief, and I'm going to be
brief because this is not a

452
00:26:30,930 --> 00:26:35,260
statistics, course, inferential
statistics is

453
00:26:35,260 --> 00:26:39,440
based upon one guiding
principle.

454
00:26:39,440 --> 00:26:58,200
And that principle is that a
random sample tends to exhibit

455
00:26:58,200 --> 00:27:09,500
the same properties
as the population

456
00:27:09,500 --> 00:27:10,750
from which it is drawn.

457
00:27:10,750 --> 00:27:18,550

458
00:27:18,550 --> 00:27:22,110
So if I try and sample people,
say, for predicting an

459
00:27:22,110 --> 00:27:26,820
election, the notion is if I go
and I asked a 1,000 people

460
00:27:26,820 --> 00:27:30,710
at random in Massachusetts who
they're going to vote for, the

461
00:27:30,710 --> 00:27:34,570
average will be about the same
as if I looked at the whole

462
00:27:34,570 --> 00:27:35,820
population.

463
00:27:35,820 --> 00:27:37,550

464
00:27:37,550 --> 00:27:41,940
So whenever we use a statistical
method like this,

465
00:27:41,940 --> 00:27:46,610
so for example, we assumed here,
is those 100,000 times I

466
00:27:46,610 --> 00:27:50,730
threw the pair of dice, that
that would be representative

467
00:27:50,730 --> 00:27:54,460
of all possible throws of the
dice, the infinite number of

468
00:27:54,460 --> 00:27:55,710
possible throws.

469
00:27:55,710 --> 00:27:58,890

470
00:27:58,890 --> 00:28:04,210
One always has to ask the
question whether this is true,

471
00:28:04,210 --> 00:28:06,810
or whether one has a sampling
technique that is, for

472
00:28:06,810 --> 00:28:09,560
example, giving you
a biased sample.

473
00:28:09,560 --> 00:28:13,260
Little later in the term, we'll
talk about many ways in

474
00:28:13,260 --> 00:28:17,730
which you can get fooled here
and think you're doing a fair

475
00:28:17,730 --> 00:28:21,190
statistical analysis, and get
all the math right, and still

476
00:28:21,190 --> 00:28:25,190
come up with the wrong answer
because this assumption

477
00:28:25,190 --> 00:28:27,480
doesn't actually hold.

478
00:28:27,480 --> 00:28:28,240
All right.

479
00:28:28,240 --> 00:28:31,360
Let's think about it now in
terms of coins, a little

480
00:28:31,360 --> 00:28:34,590
simpler than dice, where you
can flip a coin and you get

481
00:28:34,590 --> 00:28:35,840
either a head or a tail.

482
00:28:35,840 --> 00:28:38,250

483
00:28:38,250 --> 00:28:42,120
Suppose Harvey Dent, for
example, flipped a coin and it

484
00:28:42,120 --> 00:28:43,370
came up heads.

485
00:28:43,370 --> 00:28:45,500

486
00:28:45,500 --> 00:28:48,980
Would you feel good inferring
from that that the next time

487
00:28:48,980 --> 00:28:51,100
he flipped a coin it would
also come up heads?

488
00:28:51,100 --> 00:28:54,510

489
00:28:54,510 --> 00:28:56,310
I wouldn't.

490
00:28:56,310 --> 00:28:58,150
Suppose he flipped it
heads and it came up

491
00:28:58,150 --> 00:29:00,920
heads twice, in a row.

492
00:29:00,920 --> 00:29:02,510
Would you feel comfortable
with the third

493
00:29:02,510 --> 00:29:05,410
flip would be a head?

494
00:29:05,410 --> 00:29:07,540
Probably not.

495
00:29:07,540 --> 00:29:11,870
But suppose he flipped it a 100
times in a row, and it was

496
00:29:11,870 --> 00:29:13,040
a head each time.

497
00:29:13,040 --> 00:29:15,590
What would you infer?

498
00:29:15,590 --> 00:29:19,820
I would infer that the coin
two-headed And, in fact, every

499
00:29:19,820 --> 00:29:22,530
time it was going to come up
heads, because it is so

500
00:29:22,530 --> 00:29:26,070
improbable that if it
was a fair coin--

501
00:29:26,070 --> 00:29:28,290
what's the probability of having
a 100 heads in a row

502
00:29:28,290 --> 00:29:29,540
with a fair coin?

503
00:29:29,540 --> 00:29:32,170

504
00:29:32,170 --> 00:29:34,525
1 over what?

505
00:29:34,525 --> 00:29:37,129
AUDIENCE: 1 over 100--

506
00:29:37,129 --> 00:29:39,021
1 over 2 to the 100th.

507
00:29:39,021 --> 00:29:39,967
Right?

508
00:29:39,967 --> 00:29:42,600
PROFESSOR: A half the
first time times a

509
00:29:42,600 --> 00:29:43,830
half times a half.

510
00:29:43,830 --> 00:29:47,550
A huge number, a very small
number rather, right?

511
00:29:47,550 --> 00:29:51,370
So the probability and a fair
coin of getting hundred heads

512
00:29:51,370 --> 00:29:56,360
in a row is so low with just 100
flips, that I would begin

513
00:29:56,360 --> 00:30:00,910
to think that the coin
was not fair.

514
00:30:00,910 --> 00:30:02,940
All right.

515
00:30:02,940 --> 00:30:10,680
Suppose, however, I flipped it
100 times and I got 52 heads

516
00:30:10,680 --> 00:30:11,930
and 48 tails.

517
00:30:11,930 --> 00:30:15,760

518
00:30:15,760 --> 00:30:18,700
Well, I wouldn't assume
anything from that.

519
00:30:18,700 --> 00:30:22,110
Would I assume that the next
time I flipped it a 100 times

520
00:30:22,110 --> 00:30:26,380
I'd get the same
52 to 48 ratio?

521
00:30:26,380 --> 00:30:27,670
Probably not, right?

522
00:30:27,670 --> 00:30:31,940
Your common sense tells
you you wouldn't.

523
00:30:31,940 --> 00:30:33,360
All right.

524
00:30:33,360 --> 00:30:36,010
Probably, it tells you, you
wouldn't even feel comfortable

525
00:30:36,010 --> 00:30:37,520
guessing that there would
be more heads than

526
00:30:37,520 --> 00:30:38,770
tails the next time.

527
00:30:38,770 --> 00:30:42,860

528
00:30:42,860 --> 00:30:47,310
So when we think about these
things, we have to think about

529
00:30:47,310 --> 00:30:53,830
the number of tests and how
close the answer is to what

530
00:30:53,830 --> 00:30:57,920
you would get if you did
things at random.

531
00:30:57,920 --> 00:30:59,210
This is sort of comparing--

532
00:30:59,210 --> 00:31:01,830
this is technically called
comparing something to the

533
00:31:01,830 --> 00:31:03,980
null hypothesis.

534
00:31:03,980 --> 00:31:06,760
The null hypothesis is
what you would get

535
00:31:06,760 --> 00:31:09,110
with a random event.

536
00:31:09,110 --> 00:31:16,080
And when you do a simulation,
if you get something that is

537
00:31:16,080 --> 00:31:19,420
far from that, or when you
sample a population, you get

538
00:31:19,420 --> 00:31:22,950
something that's distant from
the null hypothesis, you can

539
00:31:22,950 --> 00:31:26,990
assume that maybe you're
seeing something real.

540
00:31:26,990 --> 00:31:27,250
All right.

541
00:31:27,250 --> 00:31:30,130
Let's look at this in a little
less abstract way.

542
00:31:30,130 --> 00:31:40,860

543
00:31:40,860 --> 00:31:43,600
So let's go look at
some coin flips.

544
00:31:43,600 --> 00:31:47,590
So I wrote a simple
program, flip.

545
00:31:47,590 --> 00:31:54,130
Just flip the coin some number
of times and tells me what

546
00:31:54,130 --> 00:31:55,380
fraction came up heads.

547
00:31:55,380 --> 00:32:00,260

548
00:32:00,260 --> 00:32:04,460
So we can run it, and
let's look at a--

549
00:32:04,460 --> 00:32:11,402
suppose I flip a 100,
I get 0.55.

550
00:32:11,402 --> 00:32:15,440
If I flip 10, I get 0.4.

551
00:32:15,440 --> 00:32:23,490
If I flip 10 again, I get 0.5.

552
00:32:23,490 --> 00:32:28,990
Now look at that, the same
thing twice in a row

553
00:32:28,990 --> 00:32:31,330
but now I get 0.2.

554
00:32:31,330 --> 00:32:36,330
So obviously, I shouldn't infer
too much from 10 flips

555
00:32:36,330 --> 00:32:39,030
and even from 100 where
I got 0.55.

556
00:32:39,030 --> 00:32:45,350
Let's see what happens if I
flip 100 again, 0.41, big

557
00:32:45,350 --> 00:32:47,870
difference.

558
00:32:47,870 --> 00:32:51,170
So this is suggesting that we
can't feel very good about

559
00:32:51,170 --> 00:32:53,610
what happens here.

560
00:32:53,610 --> 00:33:08,330
Now if I do the following, well
I'm feeling a little bit

561
00:33:08,330 --> 00:33:13,090
better about this, well
for one bad reason

562
00:33:13,090 --> 00:33:14,110
and one good reason.

563
00:33:14,110 --> 00:33:17,900
The bad reason is, I know the
answers 0.5, and these are

564
00:33:17,900 --> 00:33:20,805
both close to 0.5, so I
feel warm and fuzzy.

565
00:33:20,805 --> 00:33:21,900
But that's cheating.

566
00:33:21,900 --> 00:33:23,700
I wouldn't need to write
the simulation

567
00:33:23,700 --> 00:33:25,820
If I knew the answer.

568
00:33:25,820 --> 00:33:29,530
But mostly I feel good about it
because I'm getting kind of

569
00:33:29,530 --> 00:33:31,150
the same answer every time.

570
00:33:31,150 --> 00:33:34,060

571
00:33:34,060 --> 00:33:37,050
OK, and that's important.

572
00:33:37,050 --> 00:33:42,540
The more I do, the more stable
it gets with the larger the

573
00:33:42,540 --> 00:33:45,070
number of trials.

574
00:33:45,070 --> 00:33:50,470
This is an example of what's
called "the law of large

575
00:33:50,470 --> 00:34:10,780
numbers", also known as
Bernoulli's Law, after one of

576
00:34:10,780 --> 00:34:13,210
the Bernoulli family of
mathematicians, and I can't

577
00:34:13,210 --> 00:34:15,889
for the life of me remember
which Bernoulli.

578
00:34:15,889 --> 00:34:18,290
There are a whole
bunch of them.

579
00:34:18,290 --> 00:34:22,199
Anyway the law states, and it's
important to understand

580
00:34:22,199 --> 00:34:25,270
this because again it underlies
the inferential

581
00:34:25,270 --> 00:34:38,940
statistics, that in repeated
independent tests, and it's

582
00:34:38,940 --> 00:34:44,600
important to note the word
"independent", each test has

583
00:34:44,600 --> 00:34:47,469
to be independent of
the earlier test.

584
00:34:47,469 --> 00:34:57,070
In this case, the tests are
flips of the coin with the

585
00:34:57,070 --> 00:35:11,910
same actual probability we'll
call it p, often used to

586
00:35:11,910 --> 00:35:22,030
represent probability, of an
outcome for each test, the

587
00:35:22,030 --> 00:35:41,350
chance that the fraction of
times that outcome occurs the

588
00:35:41,350 --> 00:35:56,380
outcome that with probability,
p, converges to p as number of

589
00:35:56,380 --> 00:35:57,700
trials goes to infinity.

590
00:35:57,700 --> 00:36:09,300

591
00:36:09,300 --> 00:36:09,680
All right.

592
00:36:09,680 --> 00:36:14,240
So if I did an infinite number
of trials, the fraction of

593
00:36:14,240 --> 00:36:20,850
heads I would get in this case
would be exactly 0.5.

594
00:36:20,850 --> 00:36:24,370
Of course I can't do an infinite
number of trials.

595
00:36:24,370 --> 00:36:28,430
But that's the law of large
numbers that says the--

596
00:36:28,430 --> 00:36:36,120
Now, it's worth noting that this
law does not imply that

597
00:36:36,120 --> 00:36:42,560
if I start out with deviations
from the expected behavior,

598
00:36:42,560 --> 00:36:46,350
those deviations are likely to
be quote "evened out" by

599
00:36:46,350 --> 00:36:48,340
opposite deviations
in the future.

600
00:36:48,340 --> 00:36:51,300

601
00:36:51,300 --> 00:36:54,210
So if I happen to start by
getting a whole bunch of heads

602
00:36:54,210 --> 00:36:59,960
in a row, it does not mean that
I'm more likely to get

603
00:36:59,960 --> 00:37:02,210
tails in a subsequent trial.

604
00:37:02,210 --> 00:37:05,570

605
00:37:05,570 --> 00:37:06,370
All right.

606
00:37:06,370 --> 00:37:08,070
Because if I were--

607
00:37:08,070 --> 00:37:12,110
if that were true, then they
wouldn't be independent.

608
00:37:12,110 --> 00:37:14,940
Independent means memoryless.

609
00:37:14,940 --> 00:37:18,580
So if I have an independent
process, what happens in the

610
00:37:18,580 --> 00:37:22,810
future cannot be affected
by the past.

611
00:37:22,810 --> 00:37:25,910
And therefore, I don't
get this business

612
00:37:25,910 --> 00:37:29,740
of "they even out".

613
00:37:29,740 --> 00:37:32,140
Now people refuse
to believe this.

614
00:37:32,140 --> 00:37:36,140
If you go to any gambling place,
you'll discover that if

615
00:37:36,140 --> 00:37:39,080
people threw the roulette wheel,
if black comes up 20

616
00:37:39,080 --> 00:37:42,440
times in a row, they'll be
a rush to bet on red.

617
00:37:42,440 --> 00:37:46,910
Because everyone will say, red
is do, red is do, red is do.

618
00:37:46,910 --> 00:37:50,680
And every psychologist who has
ever done this experiment,

619
00:37:50,680 --> 00:37:52,920
finds that people don't
believe it.

620
00:37:52,920 --> 00:37:54,910
That it's not true.

621
00:37:54,910 --> 00:37:57,940
People just don't get
probability, and it happens so

622
00:37:57,940 --> 00:38:01,800
often it's got a name called
"the gambler's fallacy".

623
00:38:01,800 --> 00:38:06,780
And there's been great examples
of people going broke

624
00:38:06,780 --> 00:38:08,670
doing this.

625
00:38:08,670 --> 00:38:14,750
Now notice that the law of large
numbers here is about

626
00:38:14,750 --> 00:38:18,820
the fraction of times
I get an outcome.

627
00:38:18,820 --> 00:38:24,930
It does not imply for example,
that the absolute difference

628
00:38:24,930 --> 00:38:27,550
between the number of heads and
the number of tails will

629
00:38:27,550 --> 00:38:29,315
get smaller as I run
more trials.

630
00:38:29,315 --> 00:38:32,300

631
00:38:32,300 --> 00:38:33,060
Right?

632
00:38:33,060 --> 00:38:36,040
It doesn't say anything
at all about that.

633
00:38:36,040 --> 00:38:40,740
It says the ratio of head to
tails will approach 1, but not

634
00:38:40,740 --> 00:38:43,360
that the difference
between them.

635
00:38:43,360 --> 00:38:46,920
All right, let's look at an
example showing that off.

636
00:38:46,920 --> 00:38:53,430
So what I've got here is this
program called "flip plot".

637
00:38:53,430 --> 00:38:54,820
This is on your hand out.

638
00:38:54,820 --> 00:39:03,990

639
00:39:03,990 --> 00:39:08,710
This is just going to run this
business of flipping coins.

640
00:39:08,710 --> 00:39:10,030
I should point out just--

641
00:39:10,030 --> 00:39:12,900
I did it this way just
to show you.

642
00:39:12,900 --> 00:39:16,580
What I'm doing is each flip-- if
random.random is less than

643
00:39:16,580 --> 00:39:19,260
5, I'll call it a head,
0.5, I'll call it

644
00:39:19,260 --> 00:39:22,200
heads, otherwise a tails.

645
00:39:22,200 --> 00:39:25,160
You'll notice that it appears
that maybe I'm biasing a

646
00:39:25,160 --> 00:39:31,610
little bit, because I'm
giving 0.5 a value.

647
00:39:31,610 --> 00:39:37,250
But there are so many floating
point numbers between 0 and 1,

648
00:39:37,250 --> 00:39:41,000
that the probability of getting
exactly 0.5 is so

649
00:39:41,000 --> 00:39:43,590
small that I can ignore it.

650
00:39:43,590 --> 00:39:49,590
It isn't going to really make a
difference Random.random is

651
00:39:49,590 --> 00:39:52,900
the key issue, the key function
that's used to

652
00:39:52,900 --> 00:39:56,240
implement all the other random
functions that we

653
00:39:56,240 --> 00:39:58,980
have in that package.

654
00:39:58,980 --> 00:40:00,150
All right.

655
00:40:00,150 --> 00:40:03,700
So I'm going to do it, and
I'm going to do it

656
00:40:03,700 --> 00:40:06,030
over a range of values.

657
00:40:06,030 --> 00:40:10,030
The minimum exponent to the
maximum exponent and for

658
00:40:10,030 --> 00:40:15,710
exponent in range min x to max
x plus 1, I'm going to choose

659
00:40:15,710 --> 00:40:18,560
an x value that is 2 to that.

660
00:40:18,560 --> 00:40:21,840
So this lets me go
over a big range.

661
00:40:21,840 --> 00:40:26,090
So I'll see what happens if I
get 1 flip, and 2 flips, and 4

662
00:40:26,090 --> 00:40:31,320
and 8 and 16 and 32 et cetera.

663
00:40:31,320 --> 00:40:34,170
And then I'm going to
just do some plots.

664
00:40:34,170 --> 00:40:37,070
I'm going to plot the absolute
difference between heads and

665
00:40:37,070 --> 00:40:41,735
tails and the ratio
of heads to tails.

666
00:40:41,735 --> 00:40:45,050

667
00:40:45,050 --> 00:40:49,210
Let's see what happens
when we run that.

668
00:40:49,210 --> 00:40:52,080
Actually, probably nothing
because I didn't uncomment the

669
00:40:52,080 --> 00:40:53,330
run part of it.

670
00:40:53,330 --> 00:40:56,230

671
00:40:56,230 --> 00:40:57,480
Let's do that.

672
00:40:57,480 --> 00:41:06,600

673
00:41:06,600 --> 00:41:12,750
So I'm going to call flip plot
with 4 and 20, running from

674
00:41:12,750 --> 00:41:18,105
four trials 2 to the
4 to 2 to the 20.

675
00:41:18,105 --> 00:41:19,355
Let's see what we get.

676
00:41:19,355 --> 00:41:24,430

677
00:41:24,430 --> 00:41:29,120
Now, you may get different
things when you run at

678
00:41:29,120 --> 00:41:30,190
different times.

679
00:41:30,190 --> 00:41:31,440
In fact, you will.

680
00:41:31,440 --> 00:41:34,270

681
00:41:34,270 --> 00:41:39,440
So here we see something
kind of uninteresting.

682
00:41:39,440 --> 00:41:42,580

683
00:41:42,580 --> 00:41:47,290
Let's cheat and see what we got
the first time I ran it,

684
00:41:47,290 --> 00:41:52,220
which is on your hand out, and
I have a PowerPoint with it.

685
00:41:52,220 --> 00:41:53,360
I was--

686
00:41:53,360 --> 00:41:54,960
I knew this might happen.

687
00:41:54,960 --> 00:41:57,910
Doesn't usually, but sometimes
when you run it you get

688
00:41:57,910 --> 00:41:59,160
surprising results.

689
00:41:59,160 --> 00:42:02,310

690
00:42:02,310 --> 00:42:04,730
So here's what happened
when I first ran it.

691
00:42:04,730 --> 00:42:08,600

692
00:42:08,600 --> 00:42:10,645
Here was the difference between
heads and tails.

693
00:42:10,645 --> 00:42:13,360

694
00:42:13,360 --> 00:42:16,620
And it seems that, OK, the
difference was low, it went

695
00:42:16,620 --> 00:42:20,280
up, it went down, it went
up, it went down.

696
00:42:20,280 --> 00:42:21,810
It seemed to go down
dramatically.

697
00:42:21,810 --> 00:42:26,310

698
00:42:26,310 --> 00:42:30,590
If you remember what we just saw
when I ran it, we also saw

699
00:42:30,590 --> 00:42:33,140
something where it went up a
little bit then it went down

700
00:42:33,140 --> 00:42:35,790
and then shot up dramatically at
the end, which was why that

701
00:42:35,790 --> 00:42:37,970
scale is so funny.

702
00:42:37,970 --> 00:42:41,890
And if we look at the ratio,
what we see is it seems to

703
00:42:41,890 --> 00:42:47,490
start above 1, drop below
1, and then seems to

704
00:42:47,490 --> 00:42:50,920
converge towards 1.

705
00:42:50,920 --> 00:42:53,520
Now, I show this because I
want to make a couple of

706
00:42:53,520 --> 00:42:54,770
points of plotting.

707
00:42:54,770 --> 00:42:57,460

708
00:42:57,460 --> 00:43:00,990
Let's look at this out here.

709
00:43:00,990 --> 00:43:04,590
Looks like we have a pretty
dramatic trend

710
00:43:04,590 --> 00:43:07,920
of this linear drop.

711
00:43:07,920 --> 00:43:10,140
Do we?

712
00:43:10,140 --> 00:43:11,645
Do we actually have
a trend here?

713
00:43:11,645 --> 00:43:16,940

714
00:43:16,940 --> 00:43:19,950
Well let's think about it.

715
00:43:19,950 --> 00:43:25,690
The default behavior of the plot
command in PyLab is to

716
00:43:25,690 --> 00:43:27,100
connect points by lines.

717
00:43:27,100 --> 00:43:30,160

718
00:43:30,160 --> 00:43:32,580
How many points do I actually
have out here?

719
00:43:32,580 --> 00:43:41,770

720
00:43:41,770 --> 00:43:43,230
Well, you saw the code.

721
00:43:43,230 --> 00:43:45,650
You have the code
in the hand out.

722
00:43:45,650 --> 00:43:47,800
How many points do you think
there are out here?

723
00:43:47,800 --> 00:43:50,674

724
00:43:50,674 --> 00:43:53,548
A 1,000?

725
00:43:53,548 --> 00:43:56,430
A 100?

726
00:43:56,430 --> 00:43:58,110
3?

727
00:43:58,110 --> 00:44:00,550
2?

728
00:44:00,550 --> 00:44:00,830
2 to 3.

729
00:44:00,830 --> 00:44:01,630
Right?

730
00:44:01,630 --> 00:44:04,360
Depending on what I mean
by "out here".

731
00:44:04,360 --> 00:44:08,590
So what we see here is something
that happens a lot.

732
00:44:08,590 --> 00:44:12,120
People plot a small number of
points, connect them by a

733
00:44:12,120 --> 00:44:17,450
line, and mislead the audience
into thinking there's a trend

734
00:44:17,450 --> 00:44:19,435
when, in fact, maybe all
you have is an outlier.

735
00:44:19,435 --> 00:44:22,940

736
00:44:22,940 --> 00:44:31,060
So it's problematical here
to do it that way.

737
00:44:31,060 --> 00:44:33,480
So let's see what happens
if we change the code.

738
00:44:33,480 --> 00:44:58,170

739
00:44:58,170 --> 00:45:09,550
And what I'm going to do is
change it in two ways.

740
00:45:09,550 --> 00:45:12,830

741
00:45:12,830 --> 00:45:15,310
Well, maybe I'll change
it in one way first.

742
00:45:15,310 --> 00:45:26,290

743
00:45:26,290 --> 00:45:28,950
Uncomment.

744
00:45:28,950 --> 00:45:30,200
Uncomment.

745
00:45:30,200 --> 00:45:44,400

746
00:45:44,400 --> 00:45:50,550
So what I'm doing here is I am
plotting in a different way.

747
00:45:50,550 --> 00:45:56,390
This quote "BO" says, don't
connect it by lines but just

748
00:45:56,390 --> 00:46:01,190
put a dot as an "O" and
B says, make it blue.

749
00:46:01,190 --> 00:46:04,030
I used blue because it's
my favorite color.

750
00:46:04,030 --> 00:46:06,600
So now if we look at these
things, we'll see something

751
00:46:06,600 --> 00:46:07,850
pretty different.

752
00:46:07,850 --> 00:46:17,280

753
00:46:17,280 --> 00:46:20,816
So that's the difference between
heads and tails,

754
00:46:20,816 --> 00:46:23,420
that's the ratio.

755
00:46:23,420 --> 00:46:27,070
But now, if we look at the
difference between heads and

756
00:46:27,070 --> 00:46:32,610
tails here, what we see
is it's pretty sparse.

757
00:46:32,610 --> 00:46:36,850
So yeah, maybe there's a trend,
but maybe not, right?

758
00:46:36,850 --> 00:46:41,730
Because way out here I'm only
connecting two points, giving

759
00:46:41,730 --> 00:46:47,065
an illusion that there is a
trend but, in fact, no reason

760
00:46:47,065 --> 00:46:48,880
to believe it.

761
00:46:48,880 --> 00:46:51,700
So I always think if you're
plotting a small number of

762
00:46:51,700 --> 00:46:56,410
points, you're much better off
just plotting the points, than

763
00:46:56,410 --> 00:47:01,820
you are trying to
connect them.

764
00:47:01,820 --> 00:47:06,400
Now if we look at this one,
again, maybe we'd feel kind of

765
00:47:06,400 --> 00:47:08,400
comfortable if there is a trend
here, that there are

766
00:47:08,400 --> 00:47:10,530
several points on this line.

767
00:47:10,530 --> 00:47:16,540
We can't see much of what's
going on over here, which gets

768
00:47:16,540 --> 00:47:27,780
me to the next thing I want
to do is I'm going to use

769
00:47:27,780 --> 00:47:29,530
logarithmic axes here.

770
00:47:29,530 --> 00:47:32,360

771
00:47:32,360 --> 00:47:37,900
So PyLab.semilogx says make
the x-axis logarithmic.

772
00:47:37,900 --> 00:47:41,730
PyLab.semilogy the y-axis.

773
00:47:41,730 --> 00:47:45,710
And so in the case of the
absolute difference, I'm going

774
00:47:45,710 --> 00:47:48,460
to make both logarithmic.

775
00:47:48,460 --> 00:47:50,220
Why am I doing that?

776
00:47:50,220 --> 00:47:56,270
Because both have a large
range, and by making it

777
00:47:56,270 --> 00:47:59,450
logarithmic, I can see what's
happening at the left side in

778
00:47:59,450 --> 00:48:03,570
this case where things
are changing.

779
00:48:03,570 --> 00:48:07,160
When I look at the ratios, the
y-axis does not have a very

780
00:48:07,160 --> 00:48:10,645
large range, and so there's no
need to make it logarithmic.

781
00:48:10,645 --> 00:48:13,540

782
00:48:13,540 --> 00:48:14,790
We'll run it.

783
00:48:14,790 --> 00:48:24,840

784
00:48:24,840 --> 00:48:27,750
So here, we can see
the difference

785
00:48:27,750 --> 00:48:29,880
between heads and tails.

786
00:48:29,880 --> 00:48:33,610
And now we can see what's going
on at the left as we can

787
00:48:33,610 --> 00:48:34,860
in Figure (4).

788
00:48:34,860 --> 00:48:38,690

789
00:48:38,690 --> 00:48:42,380
And we can see things
much more clearly.

790
00:48:42,380 --> 00:48:45,770
So log scales can be
enormously useful.

791
00:48:45,770 --> 00:48:48,810

792
00:48:48,810 --> 00:48:53,190
And in fact, I use them a lot,
everyone uses them a lot but,

793
00:48:53,190 --> 00:48:57,920
again, it's very important to
observe the fact that it's

794
00:48:57,920 --> 00:49:00,180
logarithmic and not
get fooled.

795
00:49:00,180 --> 00:49:05,570

796
00:49:05,570 --> 00:49:06,820
All right.

797
00:49:06,820 --> 00:49:09,120

798
00:49:09,120 --> 00:49:14,290
So I talked about linear
scaling, logarithmic scaling

799
00:49:14,290 --> 00:49:19,340
and we now have charts where I
can, perhaps, actually reach

800
00:49:19,340 --> 00:49:23,415
some conclusion about
what's going on.

801
00:49:23,415 --> 00:49:28,500
The next question is, how
certain can I be?

802
00:49:28,500 --> 00:49:33,090
Can I really be certain that,
indeed, this should be

803
00:49:33,090 --> 00:49:34,340
converging to 1?

804
00:49:34,340 --> 00:49:37,140

805
00:49:37,140 --> 00:49:40,330
Here, if I sort of look at it,
it does look like there's kind

806
00:49:40,330 --> 00:49:45,380
of a linear trend of the
absolute difference growing as

807
00:49:45,380 --> 00:49:47,400
the number of trials grows.

808
00:49:47,400 --> 00:49:51,540
How certain can I be of that?

809
00:49:51,540 --> 00:49:56,700
You can never get absolute
certainty from sampling,

810
00:49:56,700 --> 00:49:59,140
because you could never be
sure if you haven't been

811
00:49:59,140 --> 00:50:02,170
vastly lucky or unlucky.

812
00:50:02,170 --> 00:50:04,630
That's not to say you
can't get the

813
00:50:04,630 --> 00:50:06,260
absolute correct answer.

814
00:50:06,260 --> 00:50:12,160
Maybe I could get 0.5, which
is the correct answer.

815
00:50:12,160 --> 00:50:17,180
But I can't know that that's
the correct answer.

816
00:50:17,180 --> 00:50:21,290
So now the question I want to
pursue, and it's what we'll

817
00:50:21,290 --> 00:50:27,520
cover on Thursday, is what
techniques can I use to make a

818
00:50:27,520 --> 00:50:31,650
statement of the form, I'm
certain within the following

819
00:50:31,650 --> 00:50:34,105
range that I have the
right answer.

820
00:50:34,105 --> 00:50:38,450
That I know the right answer
is highly likely to be this

821
00:50:38,450 --> 00:50:41,450
close to the answer my
simulation is giving me.

822
00:50:41,450 --> 00:50:44,410
And we'll look at how we can
make those statements and

823
00:50:44,410 --> 00:50:46,140
actually believe them.

824
00:50:46,140 --> 00:50:47,390
OK, see you on Thursday.

825
00:50:47,390 --> 00:50:51,392